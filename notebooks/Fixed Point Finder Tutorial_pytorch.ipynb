{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Fixed Point Finder algorithm on a GRU that makes a binary decision about its input.\n",
    "\n",
    "The goal of this tutorial is to learn about fixed point finding by running the algorithm on a simple data generator, a Gated Recurrent Unit (GRU) that is trained to make a binary decision, namely whether the integral of the white noise input is in total positive or negative, outputing either a +1 or a -1.\n",
    "\n",
    "Running the fixed point finder on this decision-making GRU will yield:\n",
    "1. the underlying fixed points\n",
    "2. the first order taylor series approximations around those fixed points.\n",
    "\n",
    "Doing this will exercise the concepts defined in the [Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks](https://www.mitpressjournals.org/doi/full/10.1162/NECO_a_00409). It's pretty important that you have read at least the beginning of the paper, otherwise you won't understand *why* we are doing what we are doing.\n",
    "\n",
    "Applying this technique was done with some success in the following papers\n",
    "* [Context-dependent computation by recurrent dynamics in prefrontal cortex](https://www.nature.com/articles/nature12742)\n",
    "* [A neural network that finds a naturalistic solution for the production of muscle activity](https://www.nature.com/articles/nn.4042)\n",
    "\n",
    "In this tutorial we do a few things:\n",
    "1. Train the decision making GRU\n",
    "2. Find the fixed points of the GRU.\n",
    "3. Find the jacobians ($\\partial{F}/\\partial{h}$), where $h$ is the hidden state and $F$ is the GRU and eigenvalues of those jacobians.\n",
    "4. Show how the linear dynamics explain this example. \n",
    "\n",
    "### Why do we care about fixed points? \n",
    "1. Because they show where the memory of the system is.\n",
    "2. (More importantly) One can linearize the dynamics around the fixed points and have reasonable approximations.\n",
    "\n",
    "$ F(h) = F(h^*) + F'(h^*)(h-h^*) + \\frac{1}{2}F''(h^*)(h-h^*)^2 + \\cdots$\n",
    "\n",
    "So if we expand around a fixed point $h^*$, then we can see that the first order approximation is likely to be accurate up to $(h-h^*)^2$.  Thus if $h-h^*$ is small, we likely have a very good approximation of the system.  \n",
    "\n",
    "Emprically, the volumes around which lineariation is valid needs to be studied for computational dynamics systems, such as recurrent neural networks like a GRU.\n",
    "\n",
    "Finally, assuming the linear system is a valid approximation, one can study the linearized system via standard analyses, such as eigenvalue / eigenvector decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy, JAX, Matplotlib and h5py should all be correctly installed and on the python path.\n",
    "from __future__ import print_function, division, absolute_import\n",
    "import datetime\n",
    "import h5py\n",
    "import jax.numpy as np\n",
    "from jax import jacrev, random, vmap\n",
    "from jax.experimental import optimizers\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp             # original CPU-backed NumPy\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "\n",
    "from pdb import set_trace as b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tutorial code.\n",
    "from imp import reload\n",
    "\n",
    "# You must change this to the location of computation-thru-dynamics directory.\n",
    "HOME_DIR = '/home/ubuntu/' \n",
    "\n",
    "sys.path.append(os.path.join(HOME_DIR,'computation-thru-dynamics'))\n",
    "import fixed_point_finder.decision as decision\n",
    "import fixed_point_finder.fixed_points as fp_optimize\n",
    "import fixed_point_finder.rnn as rnn\n",
    "import fixed_point_finder.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/neural-universality/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "text_field = torchtext.data.Field(lower=True, tokenize='spacy', include_lengths=True)\n",
    "\n",
    "\n",
    "class BinarySentimentModel(nn.Module):\n",
    "    def __init__(self, text_field, emb_dim, hidden_dim, rnn_cls=nn.GRU):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.text_field = text_field\n",
    "        self.vocab = text_field.vocab\n",
    "        self.emb = nn.Embedding(len(self.vocab), emb_dim, padding_idx=self.vocab.stoi[text_field.pad_token])\n",
    "        self.rnn = rnn_cls(input_size=emb_dim, hidden_size=hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.nn.utils.rnn.PackedSequence):\n",
    "            embs = torch.nn.utils.rnn.PackedSequence(self.emb(x.data), x.batch_sizes)\n",
    "        else:\n",
    "            embs = self.emb(x)\n",
    "            \n",
    "        # RNN layer returns sequence of hidden states and the final hidden state for each sequence in batch                                                                                                                                                   \n",
    "        h, h_final = self.rnn(embs)\n",
    "        logits = self.fc(h_final.squeeze(0))\n",
    "        return logits.view(-1), h\n",
    "\n",
    "def jax_rnn_from_params(params):\n",
    "    def rnn_output(x, h_0):\n",
    "        return rnn.batched_rnn_run_w_h0_pytorch(params, x, h_0)\n",
    "    return rnn_output\n",
    "    \n",
    "class BinarySentimentModelJAXd(nn.Module):\n",
    "    def __init__(self, text_field, emb_dim, hidden_dim, rnn_jax):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.text_field = text_field\n",
    "        self.vocab = text_field.vocab\n",
    "        self.emb = nn.Embedding(len(self.vocab), emb_dim, padding_idx=self.vocab.stoi[text_field.pad_token])\n",
    "        # self.rnn = rnn_cls(input_size=emb_dim, hidden_size=hidden_dim)\n",
    "        self.rnn = rnn_jax\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.nn.utils.rnn.PackedSequence):\n",
    "            embs = torch.nn.utils.rnn.PackedSequence(self.emb(x.data), x.batch_sizes)\n",
    "        else:\n",
    "            embs = self.emb(x)\n",
    "        \n",
    "        h_0 = np.zeros((x.shape[1], self.hidden_dim))  # (n_batch x hidden_dim)\n",
    "        # RNN layer returns sequence of hidden states and the final hidden state for each sequence in batch                                                                                                                                                   \n",
    "        h, h_final = self.rnn(torch.transpose(embs.data, 0, 1).cpu().numpy(), h_0)\n",
    "        \n",
    "        logits = self.fc(torch.tensor(onp.array(h_final)).cuda())\n",
    "        \n",
    "        return logits.view(-1), h\n",
    "        # logits.view(-1):  (batch_size,)\n",
    "        # h:  (batch_size, seq_len, hidden_dim)\n",
    "    \n",
    "    \n",
    "class Examples(object):\n",
    "    def __init__(self, batches):\n",
    "        self.batches = batches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            x = torch.nn.utils.rnn.pack_padded_sequence(batch.text[0], lengths=batch.text[1].cpu())\n",
    "            y = (batch.label - 1).float()  # labels are [<unk>, neg, pos]                                                                                                                                                                                     \n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/ubuntu/anaconda3/envs/neural-universality/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_data(\n",
    "        data_root, vocab_min_freq, batch_size,\n",
    "        device='cuda:0', preprocessed_path=None):\n",
    "    logger.info('Loading and preprocessing IMDB data')\n",
    "    try:\n",
    "        tokenize = 'spacy' if (preprocessed_path is None) else None\n",
    "        text_field = torchtext.data.Field(lower=True, tokenize=tokenize, include_lengths=True)\n",
    "    except:\n",
    "        raise RuntimeError('Ensure that spacy is installed with `conda install spacy` and that the spacy English '\n",
    "                           'models are downloaded with `spacy download en`')\n",
    "    label_field = torchtext.data.Field(sequential=False)\n",
    "    train_data, test_data = torchtext.datasets.IMDB.splits(text_field, label_field, root=data_root)\n",
    "    if preprocessed_path is not None:\n",
    "        logger.info('Loading preprocessed data from {}'.format(preprocessed_path))\n",
    "        train_examples, test_examples = torch.load(preprocessed_path)\n",
    "        train_data.examples = train_examples\n",
    "        test_data.examples = test_examples\n",
    "    text_field.build_vocab(train_data, min_freq=vocab_min_freq)\n",
    "    label_field.build_vocab(train_data)\n",
    "    train_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "        (train_data, test_data), batch_size=batch_size, device=device, shuffle=True,\n",
    "        repeat=False, sort_within_batch=True)\n",
    "    train_batches, test_batches = Examples(train_iter), Examples(test_iter)\n",
    "    logger.info('# train examples = %d' % len(train_data))\n",
    "    logger.info('vocabulary size = %d' % len(text_field.vocab))\n",
    "    return train_batches, test_batches, text_field, label_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 20:58:26,463 INFO     Loading and preprocessing IMDB data\n",
      "/home/ubuntu/anaconda3/envs/neural-universality/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_root = '/tmp'\n",
    "vocab_min_freq = 5\n",
    "batch_size = 32\n",
    "device = 'cuda:0'\n",
    "preprocessed_path = None\n",
    "\n",
    "\n",
    "try:\n",
    "    train_batches, test_batches, text_field, label_field = pickle.load(open('data.pkl', 'rb'))\n",
    "except:\n",
    "    train_batches, test_batches, text_field, label_field = load_imdb_data(\n",
    "            data_root, vocab_min_freq, batch_size, device=device, preprocessed_path=preprocessed_path)\n",
    "    pickle.dump((list(train_batches), list(test_batches), text_field, label_field), open('data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(train_batches.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0][0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[text_field.vocab.itos[x] for x in batch[0][0].data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PyTorch Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell_jax = lambda h, x : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Task and Parameters\n",
    "\n",
    "# GRU and task hyperparameters\n",
    "u = 256         # Number of inputs to the GRU\n",
    "n = 128       # Number of units in the GRU\n",
    "o = 1         # Number of outputs in the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = BinarySentimentModel(text_field, u, n)\n",
    "sentiment_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')\n",
    "sentiment_model.load_state_dict(pytorch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PyTorch Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = sentiment_model(batch[0][0].cuda())[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_outputs = batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = sum(model_outputs == desired_outputs) / len(desired_outputs)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PyTorch GRU to JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rnn_params = {\n",
    "    'weight_ih_l0': pytorch_params['rnn.weight_ih_l0'],\n",
    "    'weight_hh_l0': pytorch_params['rnn.weight_hh_l0'],\n",
    "    'bias_ih_l0': pytorch_params['rnn.bias_ih_l0'],\n",
    "    'bias_hh_l0': pytorch_params['rnn.bias_hh_l0'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rnn_params_numpy = {\n",
    "    'weight_ih_l0': pytorch_params['rnn.weight_ih_l0'].cpu().numpy(),\n",
    "    'weight_hh_l0': pytorch_params['rnn.weight_hh_l0'].cpu().numpy(),\n",
    "    'bias_ih_l0': pytorch_params['rnn.bias_ih_l0'].cpu().numpy(),\n",
    "    'bias_hh_l0': pytorch_params['rnn.bias_hh_l0'].cpu().numpy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert between PyTorch and JAX format\n",
    "\n",
    "(pytorch_rnn_params['weight_ih_l0'].shape,  # (W_ir|W_iz|W_in), (3*hidden_size, input_size)\n",
    "pytorch_rnn_params['weight_hh_l0'].shape,  # (W_hr|W_hz|W_hn), (3*hidden_size, hidden_size)\n",
    "pytorch_rnn_params['bias_ih_l0'].shape, # (b_ir|b_iz|b_in), (3*hidden_size)\n",
    "pytorch_rnn_params['bias_hh_l0'].shape,) # (b_hr|b_hz|b_hn), (3*hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ir, W_iz, W_in = np.split(pytorch_rnn_params['weight_ih_l0'].cpu().numpy(), 3)\n",
    "W_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hr, W_hz, W_hn = np.split(pytorch_rnn_params['weight_hh_l0'].cpu().numpy(), 3)\n",
    "W_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ir, b_iz, b_in = np.split(pytorch_rnn_params['bias_ih_l0'].cpu().numpy(), 3)\n",
    "b_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_hr, b_hz, b_hn = np.split(pytorch_rnn_params['bias_hh_l0'].cpu().numpy(), 3)\n",
    "b_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_in.shape, b_hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sequence_jax = jax_rnn_from_params(pytorch_rnn_params_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_rnn = torch.nn.GRU(input_size=256, hidden_size=128)\n",
    "# pytorch_rnn.load_state_dict(pytorch_rnn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_name in pytorch_params.keys():\n",
    "#     print(param_name + ': ', pytorch_params[param_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "\n",
    "# have to do some surgery on these parameters...\n",
    "# rnn_fun = lambda h : rnn.gru(pytorch_params_renamed, h, x_star)  # change this definition?\n",
    "# rnn_fun = lambda h : pytorch_rnn(torch.tensor(x_star), torch.tensor(h))\n",
    "rnn_fun = lambda h : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x_star)  # change this definition?\n",
    "batch_rnn_fun = vmap(rnn_fun, in_axes=(0,))\n",
    "\n",
    "\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_model_jax = BinarySentimentModelJAXd(text_field, u, n, rnn_sequence_jax)\n",
    "sentiment_model_jax.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')\n",
    "del pytorch_params['rnn.weight_ih_l0']\n",
    "del pytorch_params['rnn.weight_hh_l0']\n",
    "del pytorch_params['rnn.bias_ih_l0']\n",
    "del pytorch_params['rnn.bias_hh_l0']\n",
    "sentiment_model_jax.load_state_dict(pytorch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test JAX Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, hiddens = sentiment_model_jax(\n",
    "     # batched\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = (logits > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_outputs = batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = sum(model_outputs == desired_outputs) / len(desired_outputs)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[text_field.vocab.itos[x] for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Print the batch itself (convert embeddings to language tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like JAX-PyTorch hybrid model is working!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Typical Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how good this trained integrator is\n",
    "'''def inputs_targets_no_h0s(keys):\n",
    "    inputs_b, targets_b, masks_b = \\\n",
    "        decision.build_inputs_and_targets_jit(input_params, keys)\n",
    "    h0s_b = None # Use trained h0\n",
    "    masks_b = None # Not used\n",
    "    return inputs_b, targets_b, masks_b, h0s_b\n",
    "\n",
    "rnn_run = lambda inputs: rnn.batched_rnn_run_pytorch(params, inputs)\n",
    "\n",
    "give_trained_h0 = lambda batch_size : np.array([params['h0']] * batch_size)\n",
    "\n",
    "nexamples = 400\n",
    "rnn_internals = rnn.run_trials(rnn_run, inputs_targets_no_h0s, 1, nexamples)\n",
    "\n",
    "decision.plot_batch(input_params, rnn_internals['inputs'], \n",
    "                    rnn_internals['targets'], rnn_internals['outputs'], \n",
    "                    onp.abs(rnn_internals['targets'] - rnn_internals['outputs']), ntoplot=10)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed point analysis\n",
    "\n",
    "Now that we've loaded this GRU to determine whether sentiment is positive or negative, we can analyze the system via fixed point analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some preliminaries. \n",
    "x_star = np.zeros(u)  # We always linearize the input around zero in this example.\n",
    "\n",
    "# Make a one parameter function of thie hidden state, useful for jacobians.\n",
    "rnn_fun = lambda h : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x_star) #  rnn.gru(params, h, x_star)\n",
    "batch_rnn_fun = vmap(rnn_fun, in_axes=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some functions that define the fixed point loss\n",
    "which is just the squared error of a point $(h - F(h))^2$ for a discrete time system such as a GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_loss_fun = fp_optimize.get_fp_loss_fun(rnn_fun)\n",
    "total_fp_loss_fun = fp_optimize.get_total_fp_loss_fun(rnn_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_internals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to start the fixed point finder with some points, and it's always \n",
    "best to start with examples of where the state normally operates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_candidates = hiddens  # was batch x time x dim\n",
    "fp_candidates = np.reshape(fp_candidates, (-1, n)) # now batch * time x dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "32 * 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''num_batches = 1\n",
    "num_hidden_units = n\n",
    "\n",
    "fp_candidates = np.zeros((num_batches, num_hidden_units))\n",
    "fp_candidates.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed point optimization hyperparameters\n",
    "fp_num_batches = 10000         # Total number of batches to train on.\n",
    "fp_batch_size = 128          # How many examples in each batch\n",
    "fp_step_size = 0.2          # initial learning rate\n",
    "fp_decay_factor = 0.9999     # decay the learning rate this much\n",
    "fp_decay_steps = 1           #\n",
    "fp_adam_b1 = 0.9             # Adam parameters\n",
    "fp_adam_b2 = 0.999\n",
    "fp_adam_eps = 1e-5\n",
    "fp_opt_print_every = 200   # Print training information during optimziation every so often\n",
    "\n",
    "# Fixed point finding thresholds and other HPs\n",
    "fp_noise_var = 0.0      # Gaussian noise added to fixed point candidates before optimization.\n",
    "fp_opt_stop_tol = 0.00001  # Stop optimizing when the average value of the batch is below this value.\n",
    "fp_tol = 0.00001        # Discard fps with squared speed larger than this value.\n",
    "fp_unique_tol = 0.025   # tolerance for determination of identical fixed points\n",
    "fp_outlier_tol = 1.0    # Anypoint whos closest fixed point is greater than tol is an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When optimizing for fixed points, we set a few different stopping thresholds and run the fixed point finder a few times.  This is because there are rarely true numerical fixed points, though they do happen.  Instead one has slow points of varying slowness.  My experience is that if the dynamics of the slow point is very slow relative to the normal speed of the dynamics during the task / computation / behavior, then the slow point is effectively acting as a fixed point.  Moving forward, in the code, and in the comments, I always refer to slow points as fixed points, with the understanding that we are being informal. By having a few tolerances of varying slowness, we ensure we capture a large variety of the fixed points and likely get a better understanding of what the system is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#try:\n",
    "reload(fp_optimize)\n",
    "\n",
    "fp_tols = [0.0001, 0.00001]  # , 0.000001] # Used for both fp_tol and opt_stop_tol\n",
    "\n",
    "all_fps = {}\n",
    "for tol in fp_tols:\n",
    "    fp_hps = {'num_batches' : fp_num_batches, \n",
    "              'step_size' : fp_step_size, \n",
    "              'decay_factor' : fp_decay_factor, \n",
    "              'decay_steps' : fp_decay_steps, \n",
    "              'adam_b1' : fp_adam_b1, 'adam_b2' : fp_adam_b2, 'adam_eps' : fp_adam_eps,\n",
    "              'noise_var' : fp_noise_var, \n",
    "              'fp_opt_stop_tol' : tol, \n",
    "              'fp_tol' : tol, \n",
    "              'unique_tol' : fp_unique_tol, \n",
    "              'outlier_tol' : fp_outlier_tol, \n",
    "              'opt_print_every' : fp_opt_print_every}\n",
    "\n",
    "    fps, fp_losses, fp_idxs, fp_opt_details = \\\n",
    "        fp_optimize.find_fixed_points(rnn_fun, fp_candidates, fp_hps, do_print=True)  # change how rnn_fun is defined?\n",
    "    if len(fp_idxs) > 0:\n",
    "        F_of_fps = batch_rnn_fun(fps)\n",
    "    else:\n",
    "        F_of_fps = onp.zeros([0,n])\n",
    "\n",
    "    candidates = fp_candidates[fp_idxs]\n",
    "    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
    "                    'losses' : fp_losses, 'F_of_fps' : F_of_fps, \n",
    "                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
    "\n",
    "    all_fps[tol]\n",
    "#except:\n",
    "#    b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fps[.0001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the quality of the fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = plt.figure(figsize=(12,6))\n",
    "\n",
    "for tol in fp_tols:  \n",
    "    plt.semilogy(all_fps[tol]['losses']); \n",
    "    plt.xlabel('Fixed point #')\n",
    "    plt.ylabel('Fixed point loss');\n",
    "plt.legend(fp_tols)\n",
    "plt.title('Fixed point loss by fixed point (sorted) and stop tolerance')\n",
    "\n",
    "f2 = plt.figure(figsize=(12,4))\n",
    "\n",
    "pidx = 1\n",
    "nfp_tols = len(fp_tols)\n",
    "for tol_idx, tol in enumerate(fp_tols): \n",
    "    plt.subplot(1, nfp_tols, pidx); pidx += 1\n",
    "    plt.hist(onp.log10(fp_loss_fun(all_fps[tol]['fps'])), 50);\n",
    "    plt.xlabel('log10(FP loss)')\n",
    "    plt.title('Tolerance: ' + str(tol));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get a nice representation of the line using the fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rnn_params_numpy.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_jax.fc.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wO = sentiment_model_jax.fc.weight.detach().cpu().numpy()\n",
    "bO = sentiment_model_jax.fc.bias.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the best fixed points by projection onto the readoud.\n",
    "best_tol = fp_tols[-1]\n",
    "fps = all_fps[best_tol]['fps']\n",
    "fp_readouts = onp.squeeze(onp.dot(wO, fps.T) + onp.expand_dims(bO, axis=1))\n",
    "fp_ro_sidxs = onp.argsort(fp_readouts)\n",
    "sorted_fp_readouts = fp_readouts[fp_ro_sidxs]\n",
    "sorted_fps = fps[fp_ro_sidxs]\n",
    "\n",
    "downsample_fps = 2 # Use this if too many fps\n",
    "sorted_fp_readouts = sorted_fp_readouts[0:-1:downsample_fps]\n",
    "print(len(sorted_fp_readouts))\n",
    "sorted_fps = sorted_fps[0:-1:downsample_fps]\n",
    "jacs = fp_optimize.compute_jacobians(rnn_fun, sorted_fps)\n",
    "eig_decomps = fp_optimize.compute_eigenvalue_decomposition(jacs, sort_by='real', do_compute_lefts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the system starting at these fixed points, without input, and make sure the system is at equilibrium there. Note one can have fixed points that are very unstable, but that does not show up in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def no_inputs_no_targets_h0s(keys):\n",
    "    nkeys = len(keys)\n",
    "    inputs_b = np.zeros([nkeys, ntimesteps, u])\n",
    "    targets_b = np.zeros([nkeys, ntimesteps, o]) \n",
    "    h0s_b = sorted_fps[:nkeys,:]\n",
    "    masks_b = None\n",
    "    return inputs_b, targets_b, masks_b, h0s_b'''\n",
    "\n",
    "\n",
    "ntimesteps = 161\n",
    "\n",
    "def no_inputs_no_targets_h0s(keys):\n",
    "    nkeys = len(keys)\n",
    "    inputs_b = np.zeros([nkeys, ntimesteps, u])\n",
    "    targets_b = np.zeros([nkeys, ntimesteps, o]) \n",
    "    h0s_b = sorted_fps[:nkeys,:]\n",
    "    masks_b = None\n",
    "    return inputs_b, targets_b, masks_b, h0s_b\n",
    "\n",
    "\n",
    "rnn_run = lambda inputs_b, h0s_b: rnn.batched_rnn_run_w_h0_pytorch(pytorch_rnn_params_numpy, inputs_b, h0s_b)\n",
    "\n",
    "nexamples = len(sorted_fps)\n",
    "rnn_internals_slow = rnn.run_trials(rnn_run, no_inputs_no_targets_h0s, 1, nexamples)\n",
    "\n",
    "rnn.plot_examples(ntimesteps, rnn_internals_slow, 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rnn_internals_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Now, through a series of plots and dot products, we will see how the GRU solved the binary decision task. First we plot the fixed points, the fixed point candidates that the fixed point optimization was seeded with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Black shows the original candidate point, the colored stars show the fixed point, where the color of the fixed point is the projection onto the readout vector and the size is commensurate with how slow it is (slower is larger).\n",
    "\n",
    "* So in this example, we see that the fixed point structure implements an approximate line attractor, which is the one-dimensional manifold likely used to integrate the white noise and ultimately lead to the decision.\n",
    "\n",
    "* Note also the shape of the manifold relative to the color.  The color is the based on the readout value of the fixed point, so it appears that there may be three parts to the line attractor.  The middle and two sides.  The two sides may be integrating, even though the the readout would be +1 or -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "fig = plt.figure(figsize=(16,16));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "\n",
    "pca = PCA(n_components=3).fit(fp_candidates)\n",
    "\n",
    "\n",
    "max_fps_to_plot = 1000\n",
    "sizes = [100, 500]\n",
    "for tol, size in zip(fp_tols[1:2], sizes):\n",
    "    hiddens = all_fps[tol]['candidates']\n",
    "\n",
    "    h_pca = pca.transform(hiddens)\n",
    "\n",
    "    emax = h_pca.shape[0] if h_pca.shape[0] < max_fps_to_plot else max_fps_to_plot\n",
    "\n",
    "    alpha = 0.01\n",
    "    ax.scatter(h_pca[0:emax,0], h_pca[0:emax,1], h_pca[0:emax,2], color=[0, 0, 0, 0.1], s=10)\n",
    "\n",
    "    hstars = np.reshape(all_fps[tol]['fps'], (-1, n))\n",
    "    hstar_pca = pca.transform(hstars)\n",
    "    color = onp.squeeze(onp.dot(wO, hstars.T) + onp.expand_dims(bO, axis=1))\n",
    "    color = onp.where(color > 1.0, 1.0, color)\n",
    "    color = onp.where(color < -1.0, -1.0, color)\n",
    "    color = (color + 1.0) / 2.0    \n",
    "    \n",
    "    marker_style = dict(marker='*', s=size, edgecolor='gray')\n",
    "    \n",
    "    ax.scatter(hstar_pca[0:emax,0], hstar_pca[0:emax,1], hstar_pca[0:emax,2], \n",
    "                c=color[0:emax], **marker_style);\n",
    "\n",
    "    for eidx in range(emax):\n",
    "        ax.plot3D([h_pca[eidx,0], hstar_pca[eidx,0]], \n",
    "                  [h_pca[eidx,1], hstar_pca[eidx,1]],\n",
    "                  [h_pca[eidx,2], hstar_pca[eidx,2]], c=[0, 0, 1, alpha])    \n",
    "        \n",
    "plt.title('Fixed point structure and fixed point candidate starting points.');\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth taking a look at the fixed points, and the trajectories started at the fixed points, without any input, all plotted in the 3D PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,16));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "\n",
    "\n",
    "all_hiddens = onp.reshape(rnn_internals_slow['hiddens'], (-1, n))\n",
    "pca = PCA(n_components=3).fit(fp_candidates)\n",
    "\n",
    "alpha = 0.05\n",
    "emax = nexamples\n",
    "for eidx in range(emax):\n",
    "    h_pca = pca.transform(rnn_internals_slow['hiddens'][eidx,:,:])\n",
    "    ax.plot3D(h_pca[:,0], \n",
    "              h_pca[:,1],\n",
    "              h_pca[:,2], c=[0, 0, 1, alpha])    \n",
    "\n",
    "        \n",
    "size = 100\n",
    "hstar_pca = pca.transform(sorted_fps)\n",
    "color = onp.squeeze(onp.dot(wO, sorted_fps.T) + onp.expand_dims(bO, axis=1))\n",
    "color = onp.where(color > 1.0, 1.0, color)\n",
    "color = onp.where(color < -1.0, -1.0, color)\n",
    "color = (color + 1.0) / 2.0    \n",
    "marker_style = dict(marker='*', s=size, edgecolor='gray')\n",
    "\n",
    "\n",
    "ax.scatter(hstar_pca[0:emax,0], hstar_pca[0:emax,1], hstar_pca[0:emax,2], \n",
    "           c=color[0:emax], **marker_style);\n",
    "\n",
    "plt.title('High quality fixed points and the network dynamics initialized from them.');\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of linearized systems around the fixed points.\n",
    "\n",
    "Glancing up at the trained parameters plot, you can see the eigenvalues of the GRU linearized around the trained initial condition, $h_0$. These eigenvalues are plotted in the complex plane.  There is one eigenvalue very close to $(1,0)$ in the complex plane, this means the system can integrate.  The rest of the eigenvalues are within the unit circle, meaning they are stable, decaying modes.  For this example, we can safely ignore all the modes except the first one.\n",
    "\n",
    "Below, we plot the top eigenvalues as a function of the location on the readout. The top eigenvalue is very close to $(1,0)$ across the line readout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigs = 3\n",
    "plt.figure(figsize=(neigs*5, 3))\n",
    "for eidx in range(neigs):\n",
    "    max_eigs = []\n",
    "    for decomp in eig_decomps:\n",
    "        evals = decomp['evals']\n",
    "        max_eigs.append(onp.real(evals[eidx]))\n",
    "\n",
    "    max_eigs = onp.array(max_eigs)\n",
    "\n",
    "    plt.subplot(1,neigs,eidx+1)\n",
    "    plt.scatter(sorted_fp_readouts, max_eigs, c=sorted_fp_readouts);\n",
    "    plt.plot([-1,1,], [1, 1], 'k')\n",
    "    plt.axis('tight')\n",
    "    plt.title('Eigenvalue # ' + str(eidx))\n",
    "    plt.xlabel('Readout projection')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another major quantity of interest is what the right and left eigenvectors are doing.\n",
    "\n",
    "Here, we will comment exclusively on the right eigenvectors.  The right eigenvectors give the direction in which the system will integrate input.  Projecting the right eigenvectors on the readout of the GRU is a very natural thing to do then, because it shows when input is integrated to move the readout (if the readout of the right eigenvector and the readout is high), vs. when the input is integrated and does not change the readout projection (if the readout of the right eigenvector and the readout is very small, basically orthogonal).\n",
    "\n",
    "Notice that the projection between the right maximal eigenvalue and the readout varies as a function of the location of the fixed point.  This is very curious and points to how the nonlinear GRU is solving the binary decision task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldots = []\n",
    "rdots = []\n",
    "rdotla = []\n",
    "\n",
    "color = onp.squeeze(onp.dot(wO, sorted_fps.T) + onp.expand_dims(bO, axis=1))\n",
    "color = onp.where(color > 1.0, 1.0, color)\n",
    "color = onp.where(color < -1.0, -1.0, color)\n",
    "color = (color + 1.0) / 2.0    \n",
    "\n",
    "nfps = len(sorted_fps)\n",
    "for jidx in range(nfps):\n",
    "    fp = sorted_fps[jidx, :]\n",
    "    rnn_fun_x = lambda x : rnn.gru_pytorch(params, fp, x)\n",
    "    dfdx = jacrev(rnn_fun_x)\n",
    "    r0 = onp.real(eig_decomps[jidx]['R'][:, 0])                          \n",
    "    rdots.append(onp.dot(r0, wO.T))\n",
    "    l0 = onp.real(eig_decomps[jidx]['L'][:, 0])\n",
    "    ldots.append(onp.dot(l0, dfdx(onp.ones([1]))))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(sorted_fp_readouts, onp.abs(rdots), c=color)\n",
    "plt.title('Rights dotted with readout')\n",
    "plt.subplot(122)\n",
    "plt.scatter(sorted_fp_readouts, onp.abs(ldots), c=color)\n",
    "plt.title('Lefts dotted with effective input')\n",
    "plt.ylim([0, 3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three other sets of dot products give a nearly complete story. \n",
    "\n",
    "1. Dot product of fixed points with the readout as a function of where the fixed point is on the line attractor.  They are either very high, or very low.  \n",
    "2. Dot product of the local direction of the line attractor (the tangent of the line) and readout.  This shows that most of the line attractor motion is orthogonal to the readout, thus implementing something approximating a decision boundary. \n",
    "3. Dot product of the right maximal eigenvector with the local direction of the line attractor. While a bit messy, this shows that the direction local integration, as given by the right maximal eigenvector, is always lined up with the line attractor tangent, _regardless_ of the projection onto the readout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdotsla = []\n",
    "la_dots = []\n",
    "la_locs = []\n",
    "la_path_int = [0.0]\n",
    "naround = 3\n",
    "la_last = sorted_fps[naround-1,:]\n",
    "for jidx in range(naround, nfps-naround):\n",
    "    idxs = onp.arange(jidx-naround, jidx+naround+1)\n",
    "    v1 = sorted_fps[idxs[0],:]\n",
    "    v2 = sorted_fps[idxs[-1],:]\n",
    "    la = (v2-v1)/onp.linalg.norm(v2-v1) # approximate line attractor direction.\n",
    "    la_dots.append(onp.dot(la, wO.T))\n",
    "    la_locs.append(onp.squeeze(onp.dot(onp.mean(sorted_fps[idxs,:], axis=0), wO.T) + bO))\n",
    "    la_path_int.append(la_path_int[-1] + onp.linalg.norm(la-la_last))\n",
    "    la_last = la\n",
    "\n",
    "    r0 = onp.real(eig_decomps[jidx]['R'][:, 0])\n",
    "    rdotsla.append(onp.abs(onp.dot(r0, la.T)))\n",
    "\n",
    "    \n",
    "la_dots = onp.array(la_dots)\n",
    "la_locs = onp.array(la_locs)\n",
    "la_path_int = onp.array(la_path_int)\n",
    "la_path_int = la_path_int[1:]\n",
    "\n",
    "color2 = color[naround: -naround]\n",
    "    \n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(131)\n",
    "plt.scatter(la_locs, la_dots, c=color2)\n",
    "plt.xlabel('Readout of fixed point location')\n",
    "plt.title('Line attractor direction dotted with readout')\n",
    "plt.subplot(132)\n",
    "plt.scatter(la_path_int, la_dots, c=color2)\n",
    "plt.xlabel('Line attractor path integral')\n",
    "plt.title('Line attractor direction dotted with readout');\n",
    "plt.subplot(133)\n",
    "plt.scatter(la_path_int, rdotsla)\n",
    "plt.xlabel('Line attractor path integral')\n",
    "plt.title('Line attractor direction dotted with right 0 eigenvector');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to the GRU decision task.\n",
    "So it seems pretty clear how the system solved this decision task. \n",
    "* The GRU created a 1-dimensional manifold of fixed points, also known as a line attractor.  This line attractor is good at holding an analog memory, such as the integral of white noise input. \n",
    "* Local linear dynamics integrated the input along the line attractor.\n",
    "* The GRU then __bent__ and __aligned__ that line attractor, such that most path was orthogonal to the readout vector.  \n",
    "* Thus, the GRU could jump from +1 to -1 readout, while still adjusting it's confidence of the decision, based on the white noise integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment\n",
    "\n",
    "Change the error of the readout to cross-entropy error, drop the mean-squared error.  What changes, what stays the same?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
