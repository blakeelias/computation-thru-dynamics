{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Fixed Point Finder algorithm on a GRU that makes a binary decision about its input.\n",
    "\n",
    "The goal of this tutorial is to learn about fixed point finding by running the algorithm on a simple data generator, a Gated Recurrent Unit (GRU) that is trained to make a binary decision, namely whether the integral of the white noise input is in total positive or negative, outputing either a +1 or a -1.\n",
    "\n",
    "Running the fixed point finder on this decision-making GRU will yield:\n",
    "1. the underlying fixed points\n",
    "2. the first order taylor series approximations around those fixed points.\n",
    "\n",
    "Doing this will exercise the concepts defined in the [Opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks](https://www.mitpressjournals.org/doi/full/10.1162/NECO_a_00409). It's pretty important that you have read at least the beginning of the paper, otherwise you won't understand *why* we are doing what we are doing.\n",
    "\n",
    "Applying this technique was done with some success in the following papers\n",
    "* [Context-dependent computation by recurrent dynamics in prefrontal cortex](https://www.nature.com/articles/nature12742)\n",
    "* [A neural network that finds a naturalistic solution for the production of muscle activity](https://www.nature.com/articles/nn.4042)\n",
    "\n",
    "In this tutorial we do a few things:\n",
    "1. Train the decision making GRU\n",
    "2. Find the fixed points of the GRU.\n",
    "3. Find the jacobians ($\\partial{F}/\\partial{h}$), where $h$ is the hidden state and $F$ is the GRU and eigenvalues of those jacobians.\n",
    "4. Show how the linear dynamics explain this example. \n",
    "\n",
    "### Why do we care about fixed points? \n",
    "1. Because they show where the memory of the system is.\n",
    "2. (More importantly) One can linearize the dynamics around the fixed points and have reasonable approximations.\n",
    "\n",
    "$ F(h) = F(h^*) + F'(h^*)(h-h^*) + \\frac{1}{2}F''(h^*)(h-h^*)^2 + \\cdots$\n",
    "\n",
    "So if we expand around a fixed point $h^*$, then we can see that the first order approximation is likely to be accurate up to $(h-h^*)^2$.  Thus if $h-h^*$ is small, we likely have a very good approximation of the system.  \n",
    "\n",
    "Emprically, the volumes around which lineariation is valid needs to be studied for computational dynamics systems, such as recurrent neural networks like a GRU.\n",
    "\n",
    "Finally, assuming the linear system is a valid approximation, one can study the linearized system via standard analyses, such as eigenvalue / eigenvector decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copyright 2019 Google LLC\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy, JAX, Matplotlib and h5py should all be correctly installed and on the python path.\n",
    "from __future__ import print_function, division, absolute_import\n",
    "import datetime\n",
    "import h5py\n",
    "import jax.numpy as np\n",
    "from jax import jacrev, random, vmap\n",
    "from jax.experimental import optimizers\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as onp             # original CPU-backed NumPy\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "\n",
    "from pdb import set_trace as b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the tutorial code.\n",
    "from imp import reload\n",
    "\n",
    "# You must change this to the location of computation-thru-dynamics directory.\n",
    "HOME_DIR = '/home/ubuntu/' \n",
    "\n",
    "sys.path.append(os.path.join(HOME_DIR,'computation-thru-dynamics'))\n",
    "import fixed_point_finder.decision as decision\n",
    "import fixed_point_finder.fixed_points as fp_optimize\n",
    "import fixed_point_finder.rnn as rnn\n",
    "import fixed_point_finder.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/neural-universality/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "text_field = torchtext.data.Field(lower=True, tokenize='spacy', include_lengths=True)\n",
    "\n",
    "\n",
    "class BinarySentimentModel(nn.Module):\n",
    "    def __init__(self, text_field, emb_dim, hidden_dim, rnn_cls=nn.GRU):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.text_field = text_field\n",
    "        self.vocab = text_field.vocab\n",
    "        self.emb = nn.Embedding(len(self.vocab), emb_dim, padding_idx=self.vocab.stoi[text_field.pad_token])\n",
    "        self.rnn = rnn_cls(input_size=emb_dim, hidden_size=hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.nn.utils.rnn.PackedSequence):\n",
    "            embs = torch.nn.utils.rnn.PackedSequence(self.emb(x.data), x.batch_sizes)\n",
    "        else:\n",
    "            embs = self.emb(x)\n",
    "            \n",
    "        # RNN layer returns sequence of hidden states and the final hidden state for each sequence in batch                                                                                                                                                   \n",
    "        h, h_final = self.rnn(embs)\n",
    "        logits = self.fc(h_final.squeeze(0))\n",
    "        return logits.view(-1), h\n",
    "\n",
    "def jax_rnn_from_params(params):\n",
    "    def rnn_output(x, h_0):\n",
    "        return rnn.batched_rnn_run_w_h0_pytorch(params, x, h_0)\n",
    "    return rnn_output\n",
    "    \n",
    "class BinarySentimentModelJAXd(nn.Module):\n",
    "    def __init__(self, text_field, emb_dim, hidden_dim, rnn_jax):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.text_field = text_field\n",
    "        self.vocab = text_field.vocab\n",
    "        self.emb = nn.Embedding(len(self.vocab), emb_dim, padding_idx=self.vocab.stoi[text_field.pad_token])\n",
    "        # self.rnn = rnn_cls(input_size=emb_dim, hidden_size=hidden_dim)\n",
    "        self.rnn = rnn_jax\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, torch.nn.utils.rnn.PackedSequence):\n",
    "            embs = torch.nn.utils.rnn.PackedSequence(self.emb(x.data), x.batch_sizes)\n",
    "        else:\n",
    "            embs = self.emb(x)\n",
    "        \n",
    "        h_0 = np.zeros((x.shape[1], self.hidden_dim))  # (n_batch x hidden_dim)\n",
    "        # RNN layer returns sequence of hidden states and the final hidden state for each sequence in batch                                                                                                                                                   \n",
    "        h, h_final = self.rnn(torch.transpose(embs.data, 0, 1).cpu().numpy(), h_0)\n",
    "        \n",
    "        logits = self.fc(torch.tensor(onp.array(h_final)).cuda())\n",
    "        \n",
    "        return logits.view(-1), h\n",
    "        # logits.view(-1):  (batch_size,)\n",
    "        # h:  (batch_size, seq_len, hidden_dim)\n",
    "    \n",
    "    \n",
    "class Examples(object):\n",
    "    def __init__(self, batches):\n",
    "        self.batches = batches\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            x = torch.nn.utils.rnn.pack_padded_sequence(batch.text[0], lengths=batch.text[1].cpu())\n",
    "            y = (batch.label - 1).float()  # labels are [<unk>, neg, pos]                                                                                                                                                                                     \n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)-8s %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch' from '/home/ubuntu/anaconda3/envs/neural-universality/lib/python3.8/site-packages/torch/__init__.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_data(\n",
    "        data_root, vocab_min_freq, batch_size,\n",
    "        device='cuda:0', preprocessed_path=None):\n",
    "    logger.info('Loading and preprocessing IMDB data')\n",
    "    try:\n",
    "        tokenize = 'spacy' if (preprocessed_path is None) else None\n",
    "        text_field = torchtext.data.Field(lower=True, tokenize=tokenize, include_lengths=True)\n",
    "    except:\n",
    "        raise RuntimeError('Ensure that spacy is installed with `conda install spacy` and that the spacy English '\n",
    "                           'models are downloaded with `spacy download en`')\n",
    "    label_field = torchtext.data.Field(sequential=False)\n",
    "    train_data, test_data = torchtext.datasets.IMDB.splits(text_field, label_field, root=data_root)\n",
    "    if preprocessed_path is not None:\n",
    "        logger.info('Loading preprocessed data from {}'.format(preprocessed_path))\n",
    "        train_examples, test_examples = torch.load(preprocessed_path)\n",
    "        train_data.examples = train_examples\n",
    "        test_data.examples = test_examples\n",
    "    text_field.build_vocab(train_data, min_freq=vocab_min_freq)\n",
    "    label_field.build_vocab(train_data)\n",
    "    train_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "        (train_data, test_data), batch_size=batch_size, device=device, shuffle=True,\n",
    "        repeat=False, sort_within_batch=True)\n",
    "    train_batches, test_batches = Examples(train_iter), Examples(test_iter)\n",
    "    logger.info('# train examples = %d' % len(train_data))\n",
    "    logger.info('vocabulary size = %d' % len(text_field.vocab))\n",
    "    return train_batches, test_batches, text_field, label_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/tmp'\n",
    "vocab_min_freq = 5\n",
    "batch_size = 32\n",
    "device = 'cuda:0'\n",
    "preprocessed_path = None\n",
    "\n",
    "\n",
    "try:\n",
    "    train_batches, test_batches, text_field, label_field = pickle.load(open('data.pkl', 'rb'))\n",
    "except:\n",
    "    train_batches, test_batches, text_field, label_field = load_imdb_data(\n",
    "            data_root, vocab_min_freq, batch_size, device=device, preprocessed_path=preprocessed_path)\n",
    "    pickle.dump((list(train_batches), list(test_batches), text_field, label_field), open('data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = list(train_batches.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "782"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([  13, 1063,   31,  ...,    4,    4,    4], device='cuda:0'), batch_sizes=tensor([32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32,\n",
       "         32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 29, 10]), sorted_indices=None, unsorted_indices=None),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5127])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'caught',\n",
       " 'not',\n",
       " 'it',\n",
       " 'why',\n",
       " 'the',\n",
       " 'the',\n",
       " 'this',\n",
       " 'no',\n",
       " 'now',\n",
       " 'an',\n",
       " 'this',\n",
       " '<unk>',\n",
       " 'i',\n",
       " 'this',\n",
       " 'this',\n",
       " 'the',\n",
       " 'i',\n",
       " 'wow',\n",
       " 'this',\n",
       " 'well',\n",
       " 'as',\n",
       " 'terrible',\n",
       " 'gena',\n",
       " \"'\",\n",
       " 'i',\n",
       " 'i',\n",
       " 'jane',\n",
       " 'this',\n",
       " 'the',\n",
       " 'i',\n",
       " 'i',\n",
       " 'movie',\n",
       " 'the',\n",
       " 'one',\n",
       " 'has',\n",
       " 'did',\n",
       " 'beginning',\n",
       " 'subject',\n",
       " 'is',\n",
       " 'wonder',\n",
       " ',',\n",
       " 'acted',\n",
       " 'is',\n",
       " 'pope',\n",
       " 'liked',\n",
       " 'is',\n",
       " 'was',\n",
       " 'only',\n",
       " \"'m\",\n",
       " ',',\n",
       " 'series',\n",
       " ',',\n",
       " 'a',\n",
       " 'film',\n",
       " 'rowlands',\n",
       " 'the',\n",
       " 'saw',\n",
       " 'was',\n",
       " 'russell',\n",
       " 'is',\n",
       " 'minute',\n",
       " 'thought',\n",
       " 'liked',\n",
       " 'is',\n",
       " 'tail',\n",
       " 'of',\n",
       " 'very',\n",
       " 'i',\n",
       " 'of',\n",
       " 'notwithstanding',\n",
       " 'not',\n",
       " 'pamela',\n",
       " 'i',\n",
       " '/',\n",
       " 'a',\n",
       " 'plays',\n",
       " 'top',\n",
       " 'a',\n",
       " 'a',\n",
       " 'film',\n",
       " 'not',\n",
       " 'this',\n",
       " 'had',\n",
       " 'this',\n",
       " 'long',\n",
       " 'made',\n",
       " 'plays',\n",
       " 'curse',\n",
       " 'this',\n",
       " 'raised',\n",
       " 'proved',\n",
       " 'the',\n",
       " 'the',\n",
       " 'this',\n",
       " 'this',\n",
       " 'nothing',\n",
       " 'end',\n",
       " 'your',\n",
       " 'bad',\n",
       " 'waste',\n",
       " 'this',\n",
       " ',',\n",
       " 'michael',\n",
       " 'springsteen',\n",
       " \"'m\",\n",
       " 'manipulated',\n",
       " 'great',\n",
       " 'jj',\n",
       " 'gun',\n",
       " 'great',\n",
       " 'typical',\n",
       " 'i',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'potential',\n",
       " 'movie',\n",
       " '-',\n",
       " 'on',\n",
       " 'an',\n",
       " 'of',\n",
       " 'movie',\n",
       " 'in',\n",
       " 'to',\n",
       " 'perfect',\n",
       " 'forward',\n",
       " 'movie',\n",
       " '<unk>',\n",
       " 'but',\n",
       " 'of',\n",
       " 'harder',\n",
       " 'acting',\n",
       " 'my',\n",
       " 'movie',\n",
       " 'this',\n",
       " 'madsen',\n",
       " 'gave',\n",
       " 'no',\n",
       " 'documentary',\n",
       " 'idea',\n",
       " ',',\n",
       " '.',\n",
       " '<unk>',\n",
       " 'grade',\n",
       " \"'ve\",\n",
       " 'steve',\n",
       " 'was',\n",
       " ',',\n",
       " 'started',\n",
       " 'standing',\n",
       " 'a',\n",
       " 'actress',\n",
       " 'frankenstein',\n",
       " 'when',\n",
       " 'a',\n",
       " 'be',\n",
       " 'example',\n",
       " 'started',\n",
       " 'was',\n",
       " 'and',\n",
       " 'a',\n",
       " 'this',\n",
       " '-',\n",
       " '.',\n",
       " 'money',\n",
       " 'is',\n",
       " 'is',\n",
       " \"'s\",\n",
       " 'up',\n",
       " 'film',\n",
       " 'about',\n",
       " 'for',\n",
       " 'a',\n",
       " 'it',\n",
       " '/><br',\n",
       " 'b',\n",
       " 'ever',\n",
       " 'carell',\n",
       " 'so',\n",
       " 'but',\n",
       " 'out',\n",
       " 'barbra',\n",
       " 'budget',\n",
       " 'who',\n",
       " \"'\",\n",
       " 'i',\n",
       " '\"',\n",
       " 'a',\n",
       " 'of',\n",
       " ',',\n",
       " 'really',\n",
       " 'funny',\n",
       " 'religious',\n",
       " 'movie',\n",
       " 'hitting',\n",
       " 'bad',\n",
       " 'on',\n",
       " 'excellent',\n",
       " 'an',\n",
       " 'fault',\n",
       " 'acting',\n",
       " 'critic',\n",
       " 'one',\n",
       " 'a',\n",
       " 'newly',\n",
       " 'held',\n",
       " '/>i',\n",
       " 'movie',\n",
       " 'walked',\n",
       " 'fan',\n",
       " 'horrible',\n",
       " 'i',\n",
       " 'funny',\n",
       " 'fan',\n",
       " 'of',\n",
       " 'loses',\n",
       " 'sticks',\n",
       " 'was',\n",
       " 'very',\n",
       " 'delightful',\n",
       " 'something',\n",
       " 'i',\n",
       " 'really',\n",
       " '.',\n",
       " 'tract',\n",
       " 'channel',\n",
       " 'stories',\n",
       " 'story',\n",
       " 'this',\n",
       " 'with',\n",
       " 'amateur',\n",
       " ',',\n",
       " 'to',\n",
       " ',',\n",
       " 'of',\n",
       " 'film',\n",
       " 'promoted',\n",
       " 'my',\n",
       " 'first',\n",
       " 'in',\n",
       " 'out',\n",
       " 'however',\n",
       " '.',\n",
       " 'suppose',\n",
       " 'but',\n",
       " ',',\n",
       " 'about',\n",
       " 'her',\n",
       " 'faithfully',\n",
       " 'a',\n",
       " 'christian',\n",
       " 'musical',\n",
       " 'great',\n",
       " 'knew',\n",
       " 'great',\n",
       " 'i',\n",
       " 'promoting',\n",
       " 'surfing',\n",
       " ',',\n",
       " 'lines',\n",
       " 'on',\n",
       " 'tremendous',\n",
       " ',',\n",
       " 'he',\n",
       " 'become',\n",
       " 'but',\n",
       " 'the',\n",
       " 'but',\n",
       " 'food',\n",
       " 'interest',\n",
       " 'saw',\n",
       " '1940s',\n",
       " 'on',\n",
       " 'i',\n",
       " 'i',\n",
       " 'the',\n",
       " 'quickly',\n",
       " 'any',\n",
       " '$',\n",
       " 'grip',\n",
       " 'to',\n",
       " 'child',\n",
       " '\"',\n",
       " '-',\n",
       " 'going',\n",
       " 'we',\n",
       " 'because',\n",
       " 'found',\n",
       " 'classic',\n",
       " 'through',\n",
       " 'and',\n",
       " '.',\n",
       " 'the',\n",
       " 'sound',\n",
       " '<unk>',\n",
       " 'was',\n",
       " 'a',\n",
       " 'i',\n",
       " 'most',\n",
       " 'it',\n",
       " 'critic',\n",
       " '.',\n",
       " 'this',\n",
       " 'hollywood',\n",
       " '.',\n",
       " 'like',\n",
       " \"'m\",\n",
       " 'budget',\n",
       " 'deteriorated',\n",
       " 'posting',\n",
       " '<unk>',\n",
       " 'on',\n",
       " 'mary',\n",
       " '.',\n",
       " 'household',\n",
       " 'comedy',\n",
       " 'awfully',\n",
       " 'were',\n",
       " ',',\n",
       " 'this',\n",
       " 'hinduism',\n",
       " 'the',\n",
       " 'that',\n",
       " 'bad',\n",
       " 'last',\n",
       " 'and',\n",
       " 'movie',\n",
       " 'hardly',\n",
       " 'full',\n",
       " 'truly',\n",
       " 'darkest',\n",
       " ',',\n",
       " 'whose',\n",
       " 'predictable',\n",
       " 'film',\n",
       " 'and',\n",
       " 'amazing',\n",
       " 'this',\n",
       " 'so',\n",
       " 'would',\n",
       " '.',\n",
       " 'like',\n",
       " '.',\n",
       " 'reality',\n",
       " 'shelley',\n",
       " 'it',\n",
       " 'since',\n",
       " 'performer',\n",
       " 'bad',\n",
       " 'in',\n",
       " 'in',\n",
       " 'film',\n",
       " 'and',\n",
       " 'cable',\n",
       " \"'s\",\n",
       " 'characters',\n",
       " 'day',\n",
       " 'some',\n",
       " '--',\n",
       " 'in',\n",
       " '-',\n",
       " 'hated',\n",
       " 'places',\n",
       " 'unfortunately',\n",
       " 'flamboyant',\n",
       " 'plot',\n",
       " 'when',\n",
       " 'yet',\n",
       " ',',\n",
       " 'movie',\n",
       " 'glad',\n",
       " \"n't\",\n",
       " 'i',\n",
       " 'this',\n",
       " 'very',\n",
       " 'when',\n",
       " \"'s\",\n",
       " 'blew',\n",
       " 'birth',\n",
       " 'in',\n",
       " '...',\n",
       " 'for',\n",
       " 'india',\n",
       " 'to',\n",
       " 'new',\n",
       " 'movie',\n",
       " 'a',\n",
       " '.',\n",
       " 'of',\n",
       " 'nice',\n",
       " 'or',\n",
       " 'it',\n",
       " 'time',\n",
       " '\"',\n",
       " 'of',\n",
       " ',',\n",
       " ',',\n",
       " ',',\n",
       " 'it',\n",
       " 'it',\n",
       " 'since',\n",
       " 'about',\n",
       " 'i',\n",
       " 'allow',\n",
       " 'thought',\n",
       " 'will',\n",
       " 'obvious',\n",
       " 'she',\n",
       " 'story',\n",
       " 'me',\n",
       " '.',\n",
       " 'the',\n",
       " 'hence',\n",
       " 'trouble',\n",
       " 'cinemas',\n",
       " 'be',\n",
       " 'age',\n",
       " 'channels',\n",
       " 'real',\n",
       " 'you',\n",
       " 'sundance',\n",
       " 'humor',\n",
       " 'an',\n",
       " '.',\n",
       " 'photographer',\n",
       " 'september',\n",
       " '<unk>',\n",
       " 'does',\n",
       " 'overbearing',\n",
       " 'decent',\n",
       " 'came',\n",
       " 'succeeded',\n",
       " 'i',\n",
       " 'dan',\n",
       " 'did',\n",
       " 'it',\n",
       " 'it',\n",
       " 'be',\n",
       " 'miniature',\n",
       " 'witnesses',\n",
       " 'for',\n",
       " 'away',\n",
       " 'i',\n",
       " 'similarly',\n",
       " ',',\n",
       " '!',\n",
       " 'nowadays',\n",
       " 'a',\n",
       " '<unk>',\n",
       " ',',\n",
       " 'strength',\n",
       " 'should',\n",
       " '?',\n",
       " ',',\n",
       " 'effort',\n",
       " 'this',\n",
       " ';',\n",
       " '11',\n",
       " '.',\n",
       " \"n't\",\n",
       " 'mother',\n",
       " 'character',\n",
       " 'out',\n",
       " 'way',\n",
       " 'paid',\n",
       " ',',\n",
       " \"n't\",\n",
       " 'to',\n",
       " 'would',\n",
       " 'biased',\n",
       " 'sets',\n",
       " 'the',\n",
       " 'one',\n",
       " '.',\n",
       " 'was',\n",
       " 'titled',\n",
       " 'can',\n",
       " 'the',\n",
       " ',',\n",
       " 'good',\n",
       " 'dressed',\n",
       " 'and',\n",
       " 'of',\n",
       " 'never',\n",
       " 'i',\n",
       " 'but',\n",
       " 'at',\n",
       " 'movie',\n",
       " 'it',\n",
       " '\"',\n",
       " 'portrayed',\n",
       " 'turn',\n",
       " 'moves',\n",
       " 'development',\n",
       " '.',\n",
       " 'beyond',\n",
       " 'for',\n",
       " 'an',\n",
       " 'have',\n",
       " 'see',\n",
       " 'be',\n",
       " '.',\n",
       " 'used',\n",
       " 'death',\n",
       " 'word',\n",
       " 'this',\n",
       " 'saved',\n",
       " '\"',\n",
       " 'i',\n",
       " 'premise',\n",
       " 'all',\n",
       " 'family',\n",
       " 'up',\n",
       " 'was',\n",
       " 'this',\n",
       " 'see',\n",
       " 'want',\n",
       " 'once',\n",
       " 'one',\n",
       " 'was',\n",
       " \"'s\",\n",
       " '.',\n",
       " 'as',\n",
       " 'out',\n",
       " 'in',\n",
       " 'and',\n",
       " 'i',\n",
       " 'its',\n",
       " 'myself',\n",
       " 'advice',\n",
       " 'to',\n",
       " 'that',\n",
       " 'more',\n",
       " 'that',\n",
       " ',',\n",
       " 'of',\n",
       " 'of',\n",
       " 'was',\n",
       " 'before',\n",
       " 'gentlemen',\n",
       " 'advice',\n",
       " 'is',\n",
       " 'you',\n",
       " '<unk>',\n",
       " 'with',\n",
       " 'so',\n",
       " 'film',\n",
       " 'this',\n",
       " 'a',\n",
       " 'the',\n",
       " '--',\n",
       " 'just',\n",
       " 'a',\n",
       " 'this',\n",
       " 'a',\n",
       " 'to',\n",
       " 'with',\n",
       " 'story',\n",
       " 'just',\n",
       " 'expectations',\n",
       " 'and',\n",
       " 'columnist',\n",
       " 'pay',\n",
       " 'potential',\n",
       " \"'\",\n",
       " 'aside',\n",
       " 'poor',\n",
       " 'a',\n",
       " 'the',\n",
       " 'before',\n",
       " 'i',\n",
       " 'prefer',\n",
       " 'anyone',\n",
       " 'laughable',\n",
       " 'see',\n",
       " 'dirtiest',\n",
       " 'western',\n",
       " 'intrigued',\n",
       " '.',\n",
       " 'show',\n",
       " 'refund',\n",
       " 'film',\n",
       " 'which',\n",
       " 'awful',\n",
       " 'much',\n",
       " 'film',\n",
       " 'fun',\n",
       " 'be',\n",
       " 'her',\n",
       " 'line',\n",
       " 'recently',\n",
       " '.',\n",
       " 'my',\n",
       " ',',\n",
       " 'money',\n",
       " '.',\n",
       " 'adult',\n",
       " ',',\n",
       " 'acting',\n",
       " 'fan',\n",
       " 'title',\n",
       " 'the',\n",
       " 'saw',\n",
       " 'blondes',\n",
       " 'to',\n",
       " 'at',\n",
       " 'is',\n",
       " 'part',\n",
       " 'images',\n",
       " 'i',\n",
       " 'there',\n",
       " 'if',\n",
       " '...',\n",
       " 'changes',\n",
       " 'is',\n",
       " '.',\n",
       " 'better',\n",
       " 'was',\n",
       " ',',\n",
       " 'a',\n",
       " '.',\n",
       " '.',\n",
       " 'saw',\n",
       " 'why',\n",
       " 'date',\n",
       " 'who',\n",
       " 'to',\n",
       " 'an',\n",
       " 'oriented',\n",
       " 'this',\n",
       " 'and',\n",
       " 'of',\n",
       " ',',\n",
       " 'days',\n",
       " 'this',\n",
       " '\"',\n",
       " 'watch',\n",
       " 'best',\n",
       " 'skin',\n",
       " 'of',\n",
       " 'to',\n",
       " 'sought',\n",
       " 'are',\n",
       " 'you',\n",
       " 'can',\n",
       " 'into',\n",
       " 'about',\n",
       " 'if',\n",
       " 'idea',\n",
       " ',',\n",
       " 'secure',\n",
       " 'great',\n",
       " 'jj',\n",
       " 'it',\n",
       " 'this',\n",
       " '?',\n",
       " 'and',\n",
       " 'goes',\n",
       " 'see',\n",
       " 'interesting',\n",
       " \"'\",\n",
       " 'film',\n",
       " 'an',\n",
       " 'hers',\n",
       " 'which',\n",
       " 'of',\n",
       " 'movie',\n",
       " '\\x85 ',\n",
       " 'it',\n",
       " '.',\n",
       " ',',\n",
       " 'this',\n",
       " 'be',\n",
       " 'out',\n",
       " 'at',\n",
       " 'see',\n",
       " 'i',\n",
       " 'animation',\n",
       " 'as',\n",
       " 'you',\n",
       " 'to',\n",
       " 'on',\n",
       " '...',\n",
       " 'movie',\n",
       " ',',\n",
       " 'is',\n",
       " 'film',\n",
       " 'it',\n",
       " 'i',\n",
       " 'to',\n",
       " 'this',\n",
       " 'setup',\n",
       " 'humor',\n",
       " 'ranks',\n",
       " 'awful',\n",
       " '.',\n",
       " 'would',\n",
       " 'television',\n",
       " 'and',\n",
       " 'but',\n",
       " '?',\n",
       " 'the',\n",
       " 'music',\n",
       " 'movie',\n",
       " 'swallowed',\n",
       " 'the',\n",
       " 'least',\n",
       " 'it',\n",
       " 'have',\n",
       " 'it',\n",
       " 'interesting',\n",
       " 'want',\n",
       " 'have',\n",
       " 'a',\n",
       " 'but',\n",
       " '.',\n",
       " 'aghast',\n",
       " 'pretty',\n",
       " 'again',\n",
       " 'has',\n",
       " \"'m\",\n",
       " 'his',\n",
       " 'horrible',\n",
       " ',',\n",
       " 'based',\n",
       " 'as',\n",
       " 'storyline',\n",
       " 'she',\n",
       " \"n't\",\n",
       " ',',\n",
       " 'the',\n",
       " ',',\n",
       " 'well',\n",
       " 'story',\n",
       " ',',\n",
       " 'was',\n",
       " 'by',\n",
       " 'next',\n",
       " 'two',\n",
       " 'on',\n",
       " 'my',\n",
       " 'quickly',\n",
       " 'and',\n",
       " 'to',\n",
       " 'her',\n",
       " 'general',\n",
       " 'sad',\n",
       " 'what',\n",
       " 'at',\n",
       " 'similar',\n",
       " 'and',\n",
       " 'a',\n",
       " 'really',\n",
       " 'parents',\n",
       " 'movie',\n",
       " 'not',\n",
       " 'on',\n",
       " 'a',\n",
       " 'concerning',\n",
       " 'becomes',\n",
       " 'be',\n",
       " 'so',\n",
       " 'rest',\n",
       " 'sadly',\n",
       " ',',\n",
       " 'line',\n",
       " 'and',\n",
       " 'when',\n",
       " 'those',\n",
       " '<unk>',\n",
       " 'relationships',\n",
       " '.',\n",
       " '$',\n",
       " 'loses',\n",
       " 'daring',\n",
       " 'laugh',\n",
       " 'behind',\n",
       " 'basis',\n",
       " 'place',\n",
       " 'starts',\n",
       " 'this',\n",
       " 'to',\n",
       " 'it',\n",
       " 'wonderful',\n",
       " 'cheap',\n",
       " 'house',\n",
       " '.',\n",
       " 'dissimilar',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'aliens',\n",
       " 'increasingly',\n",
       " 'so',\n",
       " 'a',\n",
       " 'of',\n",
       " ',',\n",
       " 'i',\n",
       " 'was',\n",
       " 'bad',\n",
       " 'it',\n",
       " 'who',\n",
       " '/><br',\n",
       " 'in',\n",
       " 'turn',\n",
       " '16',\n",
       " 'its',\n",
       " 'as',\n",
       " 'and',\n",
       " 'a',\n",
       " ',',\n",
       " ',',\n",
       " 'out',\n",
       " 'turn',\n",
       " 'high',\n",
       " 'still',\n",
       " 'plot',\n",
       " '.',\n",
       " 'for',\n",
       " 'it',\n",
       " 'to',\n",
       " 'first',\n",
       " '.',\n",
       " 'who',\n",
       " 'deluded',\n",
       " 'bad',\n",
       " 'movie',\n",
       " 'the',\n",
       " 'this',\n",
       " 'was',\n",
       " 'even',\n",
       " 'acting',\n",
       " 'made',\n",
       " 'are',\n",
       " '/>i',\n",
       " 'which',\n",
       " 'it',\n",
       " 'back',\n",
       " 'appeal.<br',\n",
       " 'a',\n",
       " 'be',\n",
       " 'camera',\n",
       " 'bad',\n",
       " 'were',\n",
       " 'as',\n",
       " 'of',\n",
       " 'noon',\n",
       " 'holds',\n",
       " 'and',\n",
       " 'but',\n",
       " 'a',\n",
       " 'was',\n",
       " '\"',\n",
       " 'few',\n",
       " 'it',\n",
       " 'use',\n",
       " 'from',\n",
       " 'if',\n",
       " 'of',\n",
       " 'series',\n",
       " 'film',\n",
       " 'kinda',\n",
       " 'worse',\n",
       " '...',\n",
       " 'references',\n",
       " 'ignorant',\n",
       " 'really',\n",
       " 'less',\n",
       " 'off',\n",
       " '?',\n",
       " '/><br',\n",
       " 'moody',\n",
       " 'bored',\n",
       " 'than',\n",
       " '.',\n",
       " 'a',\n",
       " 'a',\n",
       " 'events',\n",
       " 'in',\n",
       " 'up',\n",
       " 'backed',\n",
       " 'my',\n",
       " 'stay',\n",
       " 'like',\n",
       " 'lost',\n",
       " 'moments',\n",
       " 'has',\n",
       " 'discarded',\n",
       " 'reality',\n",
       " 'the',\n",
       " 'this',\n",
       " 'and',\n",
       " 'squanders',\n",
       " 'obliged',\n",
       " ',',\n",
       " 'in',\n",
       " 'to',\n",
       " 'of',\n",
       " 'did',\n",
       " 'confident',\n",
       " '.',\n",
       " 'while',\n",
       " '/>one',\n",
       " 'high',\n",
       " ',',\n",
       " 'in',\n",
       " 'with',\n",
       " 'bunch',\n",
       " 'sweet',\n",
       " ',',\n",
       " 'that',\n",
       " 'to',\n",
       " 'up',\n",
       " 'brain',\n",
       " 'with',\n",
       " 'a',\n",
       " '\"',\n",
       " 'but',\n",
       " 'it',\n",
       " 'meat',\n",
       " ',',\n",
       " 'changes',\n",
       " 'magnitude',\n",
       " 'was',\n",
       " 'those',\n",
       " 'by',\n",
       " 'if',\n",
       " 'this',\n",
       " 'the',\n",
       " '<unk>',\n",
       " \"n't\",\n",
       " 'writers',\n",
       " 'or',\n",
       " 'i',\n",
       " 'of',\n",
       " 'school',\n",
       " 'go',\n",
       " 'front',\n",
       " 'the',\n",
       " 'of',\n",
       " 'and',\n",
       " 'then',\n",
       " 'the',\n",
       " 'my',\n",
       " 'by',\n",
       " 'could',\n",
       " 'his',\n",
       " 'history',\n",
       " 'it',\n",
       " 'then',\n",
       " \"'s\",\n",
       " 'from',\n",
       " 'and',\n",
       " 'were',\n",
       " ',',\n",
       " 'forced',\n",
       " 'skills',\n",
       " 'the',\n",
       " 'that',\n",
       " 'movie',\n",
       " 'new',\n",
       " 'religious',\n",
       " 'know',\n",
       " 'would',\n",
       " 'you',\n",
       " 'was',\n",
       " 'the',\n",
       " 'student',\n",
       " 'ahead',\n",
       " 'of',\n",
       " 'exception',\n",
       " 'sex',\n",
       " 'almost',\n",
       " 'blackmails',\n",
       " 'town',\n",
       " 'memory',\n",
       " 'nina',\n",
       " \"n't\",\n",
       " 'kids',\n",
       " 'nut',\n",
       " 'falls',\n",
       " 'the',\n",
       " 'flaws',\n",
       " 'a',\n",
       " 'as',\n",
       " 'any',\n",
       " 'could',\n",
       " 'to',\n",
       " '.',\n",
       " 'fact',\n",
       " 'is',\n",
       " ',',\n",
       " 'york',\n",
       " 'comparisons',\n",
       " 'what',\n",
       " 'have',\n",
       " 'be',\n",
       " 'watching',\n",
       " 'reasons',\n",
       " \"'s\",\n",
       " 'and',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text_field.vocab.itos[x] for x in batch[0][0].data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PyTorch Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cell_jax = lambda h, x : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decision Task and Parameters\n",
    "\n",
    "# GRU and task hyperparameters\n",
    "u = 256         # Number of inputs to the GRU\n",
    "n = 128       # Number of units in the GRU\n",
    "o = 1         # Number of outputs in the GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Field in module torchtext.data.field object:\n",
      "\n",
      "class Field(RawField)\n",
      " |  Field(sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n",
      " |  \n",
      " |  Defines a datatype together with instructions for converting to Tensor.\n",
      " |  \n",
      " |  Field class models common text processing datatypes that can be represented\n",
      " |  by tensors.  It holds a Vocab object that defines the set of possible values\n",
      " |  for elements of the field and their corresponding numerical representations.\n",
      " |  The Field object also holds other parameters relating to how a datatype\n",
      " |  should be numericalized, such as a tokenization method and the kind of\n",
      " |  Tensor that should be produced.\n",
      " |  \n",
      " |  If a Field is shared between two columns in a dataset (e.g., question and\n",
      " |  answer in a QA dataset), then they will have a shared vocabulary.\n",
      " |  \n",
      " |  Attributes:\n",
      " |      sequential: Whether the datatype represents sequential data. If False,\n",
      " |          no tokenization is applied. Default: True.\n",
      " |      use_vocab: Whether to use a Vocab object. If False, the data in this\n",
      " |          field should already be numerical. Default: True.\n",
      " |      init_token: A token that will be prepended to every example using this\n",
      " |          field, or None for no initial token. Default: None.\n",
      " |      eos_token: A token that will be appended to every example using this\n",
      " |          field, or None for no end-of-sentence token. Default: None.\n",
      " |      fix_length: A fixed length that all examples using this field will be\n",
      " |          padded to, or None for flexible sequence lengths. Default: None.\n",
      " |      dtype: The torch.dtype class that represents a batch of examples\n",
      " |          of this kind of data. Default: torch.long.\n",
      " |      preprocessing: The Pipeline that will be applied to examples\n",
      " |          using this field after tokenizing but before numericalizing. Many\n",
      " |          Datasets replace this attribute with a custom preprocessor.\n",
      " |          Default: None.\n",
      " |      postprocessing: A Pipeline that will be applied to examples using\n",
      " |          this field after numericalizing but before the numbers are turned\n",
      " |          into a Tensor. The pipeline function takes the batch as a list, and\n",
      " |          the field's Vocab.\n",
      " |          Default: None.\n",
      " |      lower: Whether to lowercase the text in this field. Default: False.\n",
      " |      tokenize: The function used to tokenize strings using this field into\n",
      " |          sequential examples. If \"spacy\", the SpaCy tokenizer is\n",
      " |          used. If a non-serializable function is passed as an argument,\n",
      " |          the field will not be able to be serialized. Default: string.split.\n",
      " |      tokenizer_language: The language of the tokenizer to be constructed.\n",
      " |          Various languages currently supported only in SpaCy.\n",
      " |      include_lengths: Whether to return a tuple of a padded minibatch and\n",
      " |          a list containing the lengths of each examples, or just a padded\n",
      " |          minibatch. Default: False.\n",
      " |      batch_first: Whether to produce tensors with the batch dimension first.\n",
      " |          Default: False.\n",
      " |      pad_token: The string token used as padding. Default: \"<pad>\".\n",
      " |      unk_token: The string token used to represent OOV words. Default: \"<unk>\".\n",
      " |      pad_first: Do the padding of the sequence at the beginning. Default: False.\n",
      " |      truncate_first: Do the truncating of the sequence at the beginning. Default: False\n",
      " |      stop_words: Tokens to discard during the preprocessing step. Default: None\n",
      " |      is_target: Whether this field is a target variable.\n",
      " |          Affects iteration over batches. Default: False\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Field\n",
      " |      RawField\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, dtype=torch.int64, preprocessing=None, postprocessing=None, lower=False, tokenize=None, tokenizer_language='en', include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False, truncate_first=False, stop_words=None, is_target=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  build_vocab(self, *args, **kwargs)\n",
      " |      Construct the Vocab object for this field from one or more datasets.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          Positional arguments: Dataset objects or other iterable data\n",
      " |              sources from which to construct the Vocab object that\n",
      " |              represents the set of possible values for this field. If\n",
      " |              a Dataset object is provided, all columns corresponding\n",
      " |              to this field are used; individual columns can also be\n",
      " |              provided directly.\n",
      " |          Remaining keyword arguments: Passed to the constructor of Vocab.\n",
      " |  \n",
      " |  numericalize(self, arr, device=None)\n",
      " |      Turn a batch of examples that use this field into a Variable.\n",
      " |      \n",
      " |      If the field has include_lengths=True, a tensor of lengths will be\n",
      " |      included in the return value.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          arr (List[List[str]], or tuple of (List[List[str]], List[int])):\n",
      " |              List of tokenized and padded examples, or tuple of List of\n",
      " |              tokenized and padded examples and List of lengths of each\n",
      " |              example if self.include_lengths is True.\n",
      " |          device (str or torch.device): A string or instance of `torch.device`\n",
      " |              specifying which device the Variables are going to be created on.\n",
      " |              If left as default, the tensors will be created on cpu. Default: None.\n",
      " |  \n",
      " |  pad(self, minibatch)\n",
      " |      Pad a batch of examples using this field.\n",
      " |      \n",
      " |      Pads to self.fix_length if provided, otherwise pads to the length of\n",
      " |      the longest example in the batch. Prepends self.init_token and appends\n",
      " |      self.eos_token if those attributes are not None. Returns a tuple of the\n",
      " |      padded list and a list containing lengths of each example if\n",
      " |      `self.include_lengths` is `True` and `self.sequential` is `True`, else just\n",
      " |      returns the padded list. If `self.sequential` is `False`, no padding is applied.\n",
      " |  \n",
      " |  preprocess(self, x)\n",
      " |      Load a single example using this field, tokenizing if necessary.\n",
      " |      \n",
      " |      If `sequential=True`, the input will be tokenized. Then the input\n",
      " |      will be optionally lowercased and passed to the user-provided\n",
      " |      `preprocessing` Pipeline.\n",
      " |  \n",
      " |  process(self, batch, device=None)\n",
      " |      Process a list of examples to create a torch.Tensor.\n",
      " |      \n",
      " |      Pad, numericalize, and postprocess a batch and create a tensor.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch (list(object)): A list of object from a batch of examples.\n",
      " |      Returns:\n",
      " |          torch.autograd.Variable: Processed object given the input\n",
      " |          and custom postprocessing Pipeline.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  dtypes = {torch.float32: <class 'float'>, torch.float64: <class 'float...\n",
      " |  \n",
      " |  ignore = ['dtype', 'tokenize']\n",
      " |  \n",
      " |  vocab_cls = <class 'torchtext.vocab.Vocab'>\n",
      " |      Defines a vocabulary object that will be used to numericalize a field.\n",
      " |      \n",
      " |      Attributes:\n",
      " |          freqs: A collections.Counter object holding the frequencies of tokens\n",
      " |              in the data used to build the Vocab.\n",
      " |          stoi: A collections.defaultdict instance mapping token strings to\n",
      " |              numerical identifiers.\n",
      " |          itos: A list of token strings indexed by their numerical identifiers.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RawField:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(text_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x7f2bbd699e80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarySentimentModel(\n",
       "  (emb): Embedding(31312, 256, padding_idx=1)\n",
       "  (rnn): GRU(256, 128)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = BinarySentimentModel(text_field, u, n)\n",
    "sentiment_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')\n",
    "sentiment_model.load_state_dict(pytorch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test PyTorch Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = sentiment_model(batch[0][0].cuda())[0] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_outputs = batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(model_outputs == desired_outputs) / len(desired_outputs)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PyTorch GRU to JAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rnn_params = {\n",
    "    'weight_ih_l0': pytorch_params['rnn.weight_ih_l0'],\n",
    "    'weight_hh_l0': pytorch_params['rnn.weight_hh_l0'],\n",
    "    'bias_ih_l0': pytorch_params['rnn.bias_ih_l0'],\n",
    "    'bias_hh_l0': pytorch_params['rnn.bias_hh_l0'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_rnn_params_numpy = {\n",
    "    'weight_ih_l0': pytorch_params['rnn.weight_ih_l0'].cpu().numpy(),\n",
    "    'weight_hh_l0': pytorch_params['rnn.weight_hh_l0'].cpu().numpy(),\n",
    "    'bias_ih_l0': pytorch_params['rnn.bias_ih_l0'].cpu().numpy(),\n",
    "    'bias_hh_l0': pytorch_params['rnn.bias_hh_l0'].cpu().numpy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([384, 256]),\n",
       " torch.Size([384, 128]),\n",
       " torch.Size([384]),\n",
       " torch.Size([384]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Convert between PyTorch and JAX format\n",
    "\n",
    "(pytorch_rnn_params['weight_ih_l0'].shape,  # (W_ir|W_iz|W_in), (3*hidden_size, input_size)\n",
    "pytorch_rnn_params['weight_hh_l0'].shape,  # (W_hr|W_hz|W_hn), (3*hidden_size, hidden_size)\n",
    "pytorch_rnn_params['bias_ih_l0'].shape, # (b_ir|b_iz|b_in), (3*hidden_size)\n",
    "pytorch_rnn_params['bias_hh_l0'].shape,) # (b_hr|b_hz|b_hn), (3*hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-07 19:53:20,880 WARNING  No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(128, 256)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_ir, W_iz, W_in = np.split(pytorch_rnn_params['weight_ih_l0'].cpu().numpy(), 3)\n",
    "W_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_hr, W_hz, W_hn = np.split(pytorch_rnn_params['weight_hh_l0'].cpu().numpy(), 3)\n",
    "W_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ir, b_iz, b_in = np.split(pytorch_rnn_params['bias_ih_l0'].cpu().numpy(), 3)\n",
    "b_ir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_hr, b_hz, b_hn = np.split(pytorch_rnn_params['bias_hh_l0'].cpu().numpy(), 3)\n",
    "b_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128,), (128,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_in.shape, b_hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_sequence_jax = jax_rnn_from_params(pytorch_rnn_params_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_rnn = torch.nn.GRU(input_size=256, hidden_size=128)\n",
    "# pytorch_rnn.load_state_dict(pytorch_rnn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param_name in pytorch_params.keys():\n",
    "#     print(param_name + ': ', pytorch_params[param_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "\n",
    "# have to do some surgery on these parameters...\n",
    "# rnn_fun = lambda h : rnn.gru(pytorch_params_renamed, h, x_star)  # change this definition?\n",
    "# rnn_fun = lambda h : pytorch_rnn(torch.tensor(x_star), torch.tensor(h))\n",
    "rnn_fun = lambda h : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x_star)  # change this definition?\n",
    "batch_rnn_fun = vmap(rnn_fun, in_axes=(0,))\n",
    "\n",
    "\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinarySentimentModelJAXd(\n",
       "  (emb): Embedding(31312, 256, padding_idx=1)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model_jax = BinarySentimentModelJAXd(text_field, u, n, rnn_sequence_jax)\n",
    "sentiment_model_jax.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_params = torch.load('/home/ubuntu/sentiment_models/sentiment-gru128-s1/checkpoints/model.pt')\n",
    "del pytorch_params['rnn.weight_ih_l0']\n",
    "del pytorch_params['rnn.weight_hh_l0']\n",
    "del pytorch_params['rnn.bias_ih_l0']\n",
    "del pytorch_params['rnn.bias_hh_l0']\n",
    "sentiment_model_jax.load_state_dict(pytorch_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test JAX Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, hiddens = sentiment_model_jax(\n",
    "    torch.nn.utils.rnn.pad_packed_sequence(\n",
    "        batch[0][0].cuda()\n",
    "    )[0] # batched\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = (logits > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_outputs = batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sum(model_outputs == desired_outputs) / len(desired_outputs)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO: Print the batch itself (convert embeddings to language tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like JAX-PyTorch hybrid model is working!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Typical Hidden States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def inputs_targets_no_h0s(keys):\\n    inputs_b, targets_b, masks_b =         decision.build_inputs_and_targets_jit(input_params, keys)\\n    h0s_b = None # Use trained h0\\n    masks_b = None # Not used\\n    return inputs_b, targets_b, masks_b, h0s_b\\n\\nrnn_run = lambda inputs: rnn.batched_rnn_run_pytorch(params, inputs)\\n\\ngive_trained_h0 = lambda batch_size : np.array([params['h0']] * batch_size)\\n\\nnexamples = 400\\nrnn_internals = rnn.run_trials(rnn_run, inputs_targets_no_h0s, 1, nexamples)\\n\\ndecision.plot_batch(input_params, rnn_internals['inputs'], \\n                    rnn_internals['targets'], rnn_internals['outputs'], \\n                    onp.abs(rnn_internals['targets'] - rnn_internals['outputs']), ntoplot=10)\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize how good this trained integrator is\n",
    "'''def inputs_targets_no_h0s(keys):\n",
    "    inputs_b, targets_b, masks_b = \\\n",
    "        decision.build_inputs_and_targets_jit(input_params, keys)\n",
    "    h0s_b = None # Use trained h0\n",
    "    masks_b = None # Not used\n",
    "    return inputs_b, targets_b, masks_b, h0s_b\n",
    "\n",
    "rnn_run = lambda inputs: rnn.batched_rnn_run_pytorch(params, inputs)\n",
    "\n",
    "give_trained_h0 = lambda batch_size : np.array([params['h0']] * batch_size)\n",
    "\n",
    "nexamples = 400\n",
    "rnn_internals = rnn.run_trials(rnn_run, inputs_targets_no_h0s, 1, nexamples)\n",
    "\n",
    "decision.plot_batch(input_params, rnn_internals['inputs'], \n",
    "                    rnn_internals['targets'], rnn_internals['outputs'], \n",
    "                    onp.abs(rnn_internals['targets'] - rnn_internals['outputs']), ntoplot=10)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 161, 128)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed point analysis\n",
    "\n",
    "Now that we've loaded this GRU to determine whether sentiment is positive or negative, we can analyze the system via fixed point analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some preliminaries. \n",
    "x_star = np.zeros(u)  # We always linearize the input around zero in this example.\n",
    "\n",
    "# Make a one parameter function of thie hidden state, useful for jacobians.\n",
    "rnn_fun = lambda h : rnn.gru_pytorch(pytorch_rnn_params_numpy, h, x_star) #  rnn.gru(params, h, x_star)\n",
    "batch_rnn_fun = vmap(rnn_fun, in_axes=(0,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some functions that define the fixed point loss\n",
    "which is just the squared error of a point $(h - F(h))^2$ for a discrete time system such as a GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_loss_fun = fp_optimize.get_fp_loss_fun(rnn_fun)\n",
    "total_fp_loss_fun = fp_optimize.get_total_fp_loss_fun(rnn_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_internals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to start the fixed point finder with some points, and it's always \n",
    "best to start with examples of where the state normally operates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_candidates = hiddens  # was batch x time x dim\n",
    "fp_candidates = np.reshape(fp_candidates, (-1, n)) # now batch * time x dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5152, 128)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_candidates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5152"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_batches = 1\\nnum_hidden_units = n\\n\\nfp_candidates = np.zeros((num_batches, num_hidden_units))\\nfp_candidates.shape'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''num_batches = 1\n",
    "num_hidden_units = n\n",
    "\n",
    "fp_candidates = np.zeros((num_batches, num_hidden_units))\n",
    "fp_candidates.shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed point optimization hyperparameters\n",
    "fp_num_batches = 10000         # Total number of batches to train on.\n",
    "fp_batch_size = 128          # How many examples in each batch\n",
    "fp_step_size = 0.2          # initial learning rate\n",
    "fp_decay_factor = 0.9999     # decay the learning rate this much\n",
    "fp_decay_steps = 1           #\n",
    "fp_adam_b1 = 0.9             # Adam parameters\n",
    "fp_adam_b2 = 0.999\n",
    "fp_adam_eps = 1e-5\n",
    "fp_opt_print_every = 200   # Print training information during optimziation every so often\n",
    "\n",
    "# Fixed point finding thresholds and other HPs\n",
    "fp_noise_var = 0.0      # Gaussian noise added to fixed point candidates before optimization.\n",
    "fp_opt_stop_tol = 0.00001  # Stop optimizing when the average value of the batch is below this value.\n",
    "fp_tol = 0.00001        # Discard fps with squared speed larger than this value.\n",
    "fp_unique_tol = 0.025   # tolerance for determination of identical fixed points\n",
    "fp_outlier_tol = 1.0    # Anypoint whos closest fixed point is greater than tol is an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When optimizing for fixed points, we set a few different stopping thresholds and run the fixed point finder a few times.  This is because there are rarely true numerical fixed points, though they do happen.  Instead one has slow points of varying slowness.  My experience is that if the dynamics of the slow point is very slow relative to the normal speed of the dynamics during the task / computation / behavior, then the slow point is effectively acting as a fixed point.  Moving forward, in the code, and in the comments, I always refer to slow points as fixed points, with the understanding that we are being informal. By having a few tolerances of varying slowness, we ensure we capture a large variety of the fixed points and likely get a better understanding of what the system is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing to find fixed points.\n",
      "    Batches 1-200 in 0.42 sec, Step size: 0.19604, Training loss 0.00132\n",
      "    Batches 201-400 in 0.43 sec, Step size: 0.19216, Training loss 0.00056\n",
      "    Batches 401-600 in 0.42 sec, Step size: 0.18835, Training loss 0.00034\n",
      "    Batches 601-800 in 0.42 sec, Step size: 0.18462, Training loss 0.00024\n",
      "    Batches 801-1000 in 0.43 sec, Step size: 0.18097, Training loss 0.00018\n",
      "    Batches 1001-1200 in 0.42 sec, Step size: 0.17738, Training loss 0.00015\n",
      "    Batches 1201-1400 in 0.42 sec, Step size: 0.17387, Training loss 0.00013\n",
      "    Batches 1401-1600 in 0.44 sec, Step size: 0.17043, Training loss 0.00011\n",
      "    Batches 1601-1800 in 0.43 sec, Step size: 0.16705, Training loss 0.00010\n",
      "Stopping as mean training loss 0.00010 is below tolerance 0.00010.\n",
      "Excluding fixed points with squared speed above tolerance 0.00010.\n",
      "    Kept 2971/5152 fixed points with tolerance under 0.000100.\n",
      "Excluding non-unique fixed points.\n",
      "    Kept 2951/2971 unique fixed points with uniqueness tolerance 0.025000.\n",
      "Excluding outliers.\n",
      "    Kept 820/2951 fixed points with within outlier tolerance 1.000000.\n",
      "Sorting fixed points slowest first.\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(28)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m    \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m    \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                    \u001b[0;34m'losses'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F_of_fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mF_of_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(29)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m    \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m    \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                    \u001b[0;34m'losses'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F_of_fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mF_of_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(30)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     28 \u001b[0;31m    \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
      "\u001b[0m\u001b[0;32m---> 30 \u001b[0;31m                    \u001b[0;34m'losses'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F_of_fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mF_of_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(31)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     29 \u001b[0;31m    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                    \u001b[0;34m'losses'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F_of_fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mF_of_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 31 \u001b[0;31m                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     33 \u001b[0;31m    \u001b[0mall_fps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(29)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     27 \u001b[0;31m    \u001b[0mb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m    \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfp_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 29 \u001b[0;31m    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m                    \u001b[0;34m'losses'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F_of_fps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mF_of_fps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     31 \u001b[0;31m                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(33)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     31 \u001b[0;31m                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
      "\u001b[0m\u001b[0;32m     32 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 33 \u001b[0;31m    \u001b[0mall_fps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     34 \u001b[0;31m\u001b[0;31m#except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m\u001b[0;31m#    b()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(7)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      5 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      6 \u001b[0;31m\u001b[0mall_fps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 7 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp_tols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    fp_hps = {'num_batches' : fp_num_batches, \n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m              \u001b[0;34m'step_size'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_step_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(8)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      6 \u001b[0;31m\u001b[0mall_fps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp_tols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 8 \u001b[0;31m    fp_hps = {'num_batches' : fp_num_batches, \n",
      "\u001b[0m\u001b[0;32m      9 \u001b[0;31m              \u001b[0;34m'step_size'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_step_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m              \u001b[0;34m'decay_factor'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_decay_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-71-d667b542a170>\u001b[0m(9)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      7 \u001b[0;31m\u001b[0;32mfor\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp_tols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    fp_hps = {'num_batches' : fp_num_batches, \n",
      "\u001b[0m\u001b[0;32m----> 9 \u001b[0;31m              \u001b[0;34m'step_size'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_step_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     10 \u001b[0;31m              \u001b[0;34m'decay_factor'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_decay_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     11 \u001b[0;31m              \u001b[0;34m'decay_steps'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfp_decay_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "Optimizing to find fixed points.\n",
      "    Batches 1-200 in 0.41 sec, Step size: 0.19604, Training loss 0.00132\n",
      "    Batches 201-400 in 0.43 sec, Step size: 0.19216, Training loss 0.00056\n",
      "    Batches 401-600 in 0.43 sec, Step size: 0.18835, Training loss 0.00034\n",
      "    Batches 601-800 in 0.43 sec, Step size: 0.18462, Training loss 0.00024\n",
      "    Batches 801-1000 in 0.43 sec, Step size: 0.18097, Training loss 0.00018\n",
      "    Batches 1001-1200 in 0.43 sec, Step size: 0.17738, Training loss 0.00015\n",
      "    Batches 1201-1400 in 0.43 sec, Step size: 0.17387, Training loss 0.00013\n",
      "    Batches 1401-1600 in 0.43 sec, Step size: 0.17043, Training loss 0.00011\n",
      "    Batches 1601-1800 in 0.43 sec, Step size: 0.16705, Training loss 0.00010\n",
      "    Batches 1801-2000 in 0.43 sec, Step size: 0.16374, Training loss 0.00009\n",
      "    Batches 2001-2200 in 0.44 sec, Step size: 0.16050, Training loss 0.00008\n",
      "    Batches 2201-2400 in 0.43 sec, Step size: 0.15732, Training loss 0.00007\n",
      "    Batches 2401-2600 in 0.43 sec, Step size: 0.15421, Training loss 0.00007\n",
      "    Batches 2601-2800 in 0.43 sec, Step size: 0.15115, Training loss 0.00006\n",
      "    Batches 2801-3000 in 0.43 sec, Step size: 0.14816, Training loss 0.00006\n",
      "    Batches 3001-3200 in 0.43 sec, Step size: 0.14523, Training loss 0.00006\n",
      "    Batches 3201-3400 in 0.43 sec, Step size: 0.14235, Training loss 0.00005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batches 3401-3600 in 0.43 sec, Step size: 0.13953, Training loss 0.00005\n",
      "    Batches 3601-3800 in 0.43 sec, Step size: 0.13677, Training loss 0.00005\n",
      "    Batches 3801-4000 in 0.43 sec, Step size: 0.13406, Training loss 0.00005\n",
      "    Batches 4001-4200 in 0.44 sec, Step size: 0.13141, Training loss 0.00004\n",
      "    Batches 4201-4400 in 0.44 sec, Step size: 0.12880, Training loss 0.00004\n",
      "    Batches 4401-4600 in 0.43 sec, Step size: 0.12625, Training loss 0.00004\n",
      "    Batches 4601-4800 in 0.44 sec, Step size: 0.12375, Training loss 0.00004\n",
      "    Batches 4801-5000 in 0.42 sec, Step size: 0.12130, Training loss 0.00004\n",
      "    Batches 5001-5200 in 0.42 sec, Step size: 0.11890, Training loss 0.00004\n",
      "    Batches 5201-5400 in 0.42 sec, Step size: 0.11655, Training loss 0.00004\n",
      "    Batches 5401-5600 in 0.59 sec, Step size: 0.11424, Training loss 0.00004\n",
      "    Batches 5601-5800 in 0.42 sec, Step size: 0.11198, Training loss 0.00004\n"
     ]
    }
   ],
   "source": [
    "#try:\n",
    "reload(fp_optimize)\n",
    "\n",
    "fp_tols = [0.0001, 0.00001, 0.000001] # Used for both fp_tol and opt_stop_tol\n",
    "\n",
    "all_fps = {}\n",
    "for tol in fp_tols:\n",
    "    fp_hps = {'num_batches' : fp_num_batches, \n",
    "              'step_size' : fp_step_size, \n",
    "              'decay_factor' : fp_decay_factor, \n",
    "              'decay_steps' : fp_decay_steps, \n",
    "              'adam_b1' : fp_adam_b1, 'adam_b2' : fp_adam_b2, 'adam_eps' : fp_adam_eps,\n",
    "              'noise_var' : fp_noise_var, \n",
    "              'fp_opt_stop_tol' : tol, \n",
    "              'fp_tol' : tol, \n",
    "              'unique_tol' : fp_unique_tol, \n",
    "              'outlier_tol' : fp_outlier_tol, \n",
    "              'opt_print_every' : fp_opt_print_every}\n",
    "\n",
    "    fps, fp_losses, fp_idxs, fp_opt_details = \\\n",
    "        fp_optimize.find_fixed_points(rnn_fun, fp_candidates, fp_hps, do_print=True)  # change how rnn_fun is defined?\n",
    "    if len(fp_idxs) > 0:\n",
    "        F_of_fps = batch_rnn_fun(fps)\n",
    "    else:\n",
    "        F_of_fps = onp.zeros([0,n])\n",
    "\n",
    "    b()\n",
    "    candidates = fp_candidates[fp_idxs]\n",
    "    all_fps[tol] = {'fps' : fps, 'candidates' : candidates,\n",
    "                    'losses' : fp_losses, 'F_of_fps' : F_of_fps, \n",
    "                    'opt_details' : fp_opt_details, 'hps' : fp_hps}\n",
    "\n",
    "    all_fps[tol]\n",
    "#except:\n",
    "#    b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the quality of the fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fixed_point_finder.rnn' from '/home/ubuntu/computation-thru-dynamics/fixed_point_finder/rnn.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1e-06",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-355dd410b39f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfp_tols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msemilogy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fixed point #'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fixed point loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1e-06"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1 = plt.figure(figsize=(12,6))\n",
    "\n",
    "for tol in fp_tols: \n",
    "    plt.semilogy(all_fps[tol]['losses']); \n",
    "    plt.xlabel('Fixed point #')\n",
    "    plt.ylabel('Fixed point loss');\n",
    "plt.legend(fp_tols)\n",
    "plt.title('Fixed point loss by fixed point (sorted) and stop tolerance')\n",
    "\n",
    "f2 = plt.figure(figsize=(12,4))\n",
    "\n",
    "pidx = 1\n",
    "nfp_tols = len(fp_tols)\n",
    "for tol_idx, tol in enumerate(fp_tols):\n",
    "    plt.subplot(1, nfp_tols, pidx); pidx += 1\n",
    "    plt.hist(onp.log10(fp_loss_fun(all_fps[tol]['fps'])), 50);\n",
    "    plt.xlabel('log10(FP loss)')\n",
    "    plt.title('Tolerance: ' + str(tol));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to get a nice representation of the line using the fixed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the best fixed points by projection onto the readoud.\n",
    "best_tol = fp_tols[-1]\n",
    "fps = all_fps[best_tol]['fps']\n",
    "fp_readouts = onp.squeeze(onp.dot(params['wO'], fps.T) + onp.expand_dims(params['bO'], axis=1))\n",
    "fp_ro_sidxs = onp.argsort(fp_readouts)\n",
    "sorted_fp_readouts = fp_readouts[fp_ro_sidxs]\n",
    "sorted_fps = fps[fp_ro_sidxs]\n",
    "\n",
    "downsample_fps = 2 # Use this if too many fps\n",
    "sorted_fp_readouts = sorted_fp_readouts[0:-1:downsample_fps]\n",
    "print(len(sorted_fp_readouts))\n",
    "sorted_fps = sorted_fps[0:-1:downsample_fps]\n",
    "jacs = fp_optimize.compute_jacobians(rnn_fun, sorted_fps)\n",
    "eig_decomps = fp_optimize.compute_eigenvalue_decomposition(jacs, sort_by='real', do_compute_lefts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the system starting at these fixed points, without input, and make sure the system is at equilibrium there. Note one can have fixed points that are very unstable, but that does not show up in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_inputs_no_targets_h0s(keys):\n",
    "    nkeys = len(keys)\n",
    "    inputs_b = np.zeros([nkeys, ntimesteps, u])\n",
    "    targets_b = np.zeros([nkeys, ntimesteps, o]) \n",
    "    h0s_b = sorted_fps[:nkeys,:]\n",
    "    masks_b = None\n",
    "    return inputs_b, targets_b, masks_b, h0s_b\n",
    "\n",
    "rnn_run = lambda inputs_b, h0s_b: rnn.batched_rnn_run_w_h0(params, inputs_b, h0s_b)\n",
    "\n",
    "nexamples = len(sorted_fps)\n",
    "rnn_internals_slow = rnn.run_trials(rnn_run, no_inputs_no_targets_h0s, 1, nexamples)\n",
    "\n",
    "rnn.plot_examples(ntimesteps, rnn_internals_slow, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Now, through a series of plots and dot products, we will see how the GRU solved the binary decision task. First we plot the fixed points, the fixed point candidates that the fixed point optimization was seeded with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Black shows the original candidate point, the colored stars show the fixed point, where the color of the fixed point is the projection onto the readout vector and the size is commensurate with how slow it is (slower is larger).\n",
    "\n",
    "* So in this example, we see that the fixed point structure implements an approximate line attractor, which is the one-dimensional manifold likely used to integrate the white noise and ultimately lead to the decision.\n",
    "\n",
    "* Note also the shape of the manifold relative to the color.  The color is the based on the readout value of the fixed point, so it appears that there may be three parts to the line attractor.  The middle and two sides.  The two sides may be integrating, even though the the readout would be +1 or -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "fig = plt.figure(figsize=(16,16));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "\n",
    "pca = PCA(n_components=3).fit(fp_candidates)\n",
    "\n",
    "\n",
    "max_fps_to_plot = 1000\n",
    "sizes = [100, 500]\n",
    "for tol, size in zip(fp_tols[1:2], sizes):\n",
    "    hiddens = all_fps[tol]['candidates']\n",
    "\n",
    "    h_pca = pca.transform(hiddens)\n",
    "\n",
    "    emax = h_pca.shape[0] if h_pca.shape[0] < max_fps_to_plot else max_fps_to_plot\n",
    "\n",
    "    alpha = 0.01\n",
    "    ax.scatter(h_pca[0:emax,0], h_pca[0:emax,1], h_pca[0:emax,2], color=[0, 0, 0, 0.1], s=10)\n",
    "\n",
    "    hstars = np.reshape(all_fps[tol]['fps'], (-1, n))\n",
    "    hstar_pca = pca.transform(hstars)\n",
    "    color = onp.squeeze(onp.dot(params['wO'], hstars.T) + onp.expand_dims(params['bO'], axis=1))\n",
    "    color = onp.where(color > 1.0, 1.0, color)\n",
    "    color = onp.where(color < -1.0, -1.0, color)\n",
    "    color = (color + 1.0) / 2.0    \n",
    "    \n",
    "    marker_style = dict(marker='*', s=size, edgecolor='gray')\n",
    "    \n",
    "    ax.scatter(hstar_pca[0:emax,0], hstar_pca[0:emax,1], hstar_pca[0:emax,2], \n",
    "                c=color[0:emax], **marker_style);\n",
    "\n",
    "    for eidx in range(emax):\n",
    "        ax.plot3D([h_pca[eidx,0], hstar_pca[eidx,0]], \n",
    "                  [h_pca[eidx,1], hstar_pca[eidx,1]],\n",
    "                  [h_pca[eidx,2], hstar_pca[eidx,2]], c=[0, 0, 1, alpha])    \n",
    "        \n",
    "plt.title('Fixed point structure and fixed point candidate starting points.');\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth taking a look at the fixed points, and the trajectories started at the fixed points, without any input, all plotted in the 3D PCA space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,16));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "\n",
    "\n",
    "all_hiddens = onp.reshape(rnn_internals_slow['hiddens'], (-1, n))\n",
    "pca = PCA(n_components=3).fit(fp_candidates)\n",
    "\n",
    "alpha = 0.05\n",
    "emax = nexamples\n",
    "for eidx in range(emax):\n",
    "    h_pca = pca.transform(rnn_internals_slow['hiddens'][eidx,:,:])\n",
    "    ax.plot3D(h_pca[:,0], \n",
    "              h_pca[:,1],\n",
    "              h_pca[:,2], c=[0, 0, 1, alpha])    \n",
    "\n",
    "        \n",
    "size = 100\n",
    "hstar_pca = pca.transform(sorted_fps)\n",
    "color = onp.squeeze(onp.dot(params['wO'], sorted_fps.T) + onp.expand_dims(params['bO'], axis=1))\n",
    "color = onp.where(color > 1.0, 1.0, color)\n",
    "color = onp.where(color < -1.0, -1.0, color)\n",
    "color = (color + 1.0) / 2.0    \n",
    "marker_style = dict(marker='*', s=size, edgecolor='gray')\n",
    "\n",
    "\n",
    "ax.scatter(hstar_pca[0:emax,0], hstar_pca[0:emax,1], hstar_pca[0:emax,2], \n",
    "           c=color[0:emax], **marker_style);\n",
    "\n",
    "plt.title('High quality fixed points and the network dynamics initialized from them.');\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')\n",
    "ax.set_zlabel('PC 3');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of linearized systems around the fixed points.\n",
    "\n",
    "Glancing up at the trained parameters plot, you can see the eigenvalues of the GRU linearized around the trained initial condition, $h_0$. These eigenvalues are plotted in the complex plane.  There is one eigenvalue very close to $(1,0)$ in the complex plane, this means the system can integrate.  The rest of the eigenvalues are within the unit circle, meaning they are stable, decaying modes.  For this example, we can safely ignore all the modes except the first one.\n",
    "\n",
    "Below, we plot the top eigenvalues as a function of the location on the readout. The top eigenvalue is very close to $(1,0)$ across the line readout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigs = 3\n",
    "plt.figure(figsize=(neigs*5, 3))\n",
    "for eidx in range(neigs):\n",
    "    max_eigs = []\n",
    "    for decomp in eig_decomps:\n",
    "        evals = decomp['evals']\n",
    "        max_eigs.append(onp.real(evals[eidx]))\n",
    "\n",
    "    max_eigs = onp.array(max_eigs)\n",
    "\n",
    "    plt.subplot(1,neigs,eidx+1)\n",
    "    plt.scatter(sorted_fp_readouts, max_eigs, c=sorted_fp_readouts);\n",
    "    plt.plot([-1,1,], [1, 1], 'k')\n",
    "    plt.axis('tight')\n",
    "    plt.title('Eigenvalue # ' + str(eidx))\n",
    "    plt.xlabel('Readout projection')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another major quantity of interest is what the right and left eigenvectors are doing.\n",
    "\n",
    "Here, we will comment exclusively on the right eigenvectors.  The right eigenvectors give the direction in which the system will integrate input.  Projecting the right eigenvectors on the readout of the GRU is a very natural thing to do then, because it shows when input is integrated to move the readout (if the readout of the right eigenvector and the readout is high), vs. when the input is integrated and does not change the readout projection (if the readout of the right eigenvector and the readout is very small, basically orthogonal).\n",
    "\n",
    "Notice that the projection between the right maximal eigenvalue and the readout varies as a function of the location of the fixed point.  This is very curious and points to how the nonlinear GRU is solving the binary decision task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldots = []\n",
    "rdots = []\n",
    "rdotla = []\n",
    "\n",
    "color = onp.squeeze(onp.dot(params['wO'], sorted_fps.T) + onp.expand_dims(params['bO'], axis=1))\n",
    "color = onp.where(color > 1.0, 1.0, color)\n",
    "color = onp.where(color < -1.0, -1.0, color)\n",
    "color = (color + 1.0) / 2.0    \n",
    "\n",
    "nfps = len(sorted_fps)\n",
    "for jidx in range(nfps):\n",
    "    fp = sorted_fps[jidx, :]\n",
    "    rnn_fun_x = lambda x : rnn.gru(params, fp, x)\n",
    "    dfdx = jacrev(rnn_fun_x)\n",
    "    r0 = onp.real(eig_decomps[jidx]['R'][:, 0])                          \n",
    "    rdots.append(onp.dot(r0, params['wO'].T))\n",
    "    l0 = onp.real(eig_decomps[jidx]['L'][:, 0])\n",
    "    ldots.append(onp.dot(l0, dfdx(onp.ones([1]))))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(sorted_fp_readouts, onp.abs(rdots), c=color)\n",
    "plt.title('Rights dotted with readout')\n",
    "plt.subplot(122)\n",
    "plt.scatter(sorted_fp_readouts, onp.abs(ldots), c=color)\n",
    "plt.title('Lefts dotted with effective input')\n",
    "plt.ylim([0, 3]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three other sets of dot products give a nearly complete story. \n",
    "\n",
    "1. Dot product of fixed points with the readout as a function of where the fixed point is on the line attractor.  They are either very high, or very low.  \n",
    "2. Dot product of the local direction of the line attractor (the tangent of the line) and readout.  This shows that most of the line attractor motion is orthogonal to the readout, thus implementing something approximating a decision boundary. \n",
    "3. Dot product of the right maximal eigenvector with the local direction of the line attractor. While a bit messy, this shows that the direction local integration, as given by the right maximal eigenvector, is always lined up with the line attractor tangent, _regardless_ of the projection onto the readout. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdotsla = []\n",
    "la_dots = []\n",
    "la_locs = []\n",
    "la_path_int = [0.0]\n",
    "naround = 3\n",
    "la_last = sorted_fps[naround-1,:]\n",
    "for jidx in range(naround, nfps-naround):\n",
    "    idxs = onp.arange(jidx-naround, jidx+naround+1)\n",
    "    v1 = sorted_fps[idxs[0],:]\n",
    "    v2 = sorted_fps[idxs[-1],:]\n",
    "    la = (v2-v1)/onp.linalg.norm(v2-v1) # approximate line attractor direction.\n",
    "    la_dots.append(onp.dot(la, params['wO'].T))\n",
    "    la_locs.append(onp.squeeze(onp.dot(onp.mean(sorted_fps[idxs,:], axis=0), params['wO'].T) + params['bO']))\n",
    "    la_path_int.append(la_path_int[-1] + onp.linalg.norm(la-la_last))\n",
    "    la_last = la\n",
    "\n",
    "    r0 = onp.real(eig_decomps[jidx]['R'][:, 0])\n",
    "    rdotsla.append(onp.abs(onp.dot(r0, la.T)))\n",
    "\n",
    "    \n",
    "la_dots = onp.array(la_dots)\n",
    "la_locs = onp.array(la_locs)\n",
    "la_path_int = onp.array(la_path_int)\n",
    "la_path_int = la_path_int[1:]\n",
    "\n",
    "color2 = color[naround: -naround]\n",
    "    \n",
    "plt.figure(figsize=(18,4))\n",
    "plt.subplot(131)\n",
    "plt.scatter(la_locs, la_dots, c=color2)\n",
    "plt.xlabel('Readout of fixed point location')\n",
    "plt.title('Line attractor direction dotted with readout')\n",
    "plt.subplot(132)\n",
    "plt.scatter(la_path_int, la_dots, c=color2)\n",
    "plt.xlabel('Line attractor path integral')\n",
    "plt.title('Line attractor direction dotted with readout');\n",
    "plt.subplot(133)\n",
    "plt.scatter(la_path_int, rdotsla)\n",
    "plt.xlabel('Line attractor path integral')\n",
    "plt.title('Line attractor direction dotted with right 0 eigenvector');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution to the GRU decision task.\n",
    "So it seems pretty clear how the system solved this decision task. \n",
    "* The GRU created a 1-dimensional manifold of fixed points, also known as a line attractor.  This line attractor is good at holding an analog memory, such as the integral of white noise input. \n",
    "* Local linear dynamics integrated the input along the line attractor.\n",
    "* The GRU then __bent__ and __aligned__ that line attractor, such that most path was orthogonal to the readout vector.  \n",
    "* Thus, the GRU could jump from +1 to -1 readout, while still adjusting it's confidence of the decision, based on the white noise integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment\n",
    "\n",
    "Change the error of the readout to cross-entropy error, drop the mean-squared error.  What changes, what stays the same?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
